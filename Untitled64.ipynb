{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08280b87-2da2-4674-8bcd-24c5934325f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code: MODEL_DEPLOYING\n",
      "description: \"Model is deploying\"\n",
      "details: \"Model is currently deploying or scaling up.\"\n",
      "req_id: \"b16ff36feab73c19b8f407944495fd3b\"\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Post model outputs failed, status: Model is deploying",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m post_model_outputs_response\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m!=\u001b[39m status_code_pb2\u001b[38;5;241m.\u001b[39mSUCCESS:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(post_model_outputs_response\u001b[38;5;241m.\u001b[39mstatus)\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPost model outputs failed, status: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m post_model_outputs_response\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mdescription)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Since we have one input, one output will exist here\u001b[39;00m\n\u001b[0;32m     64\u001b[0m output \u001b[38;5;241m=\u001b[39m post_model_outputs_response\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mException\u001b[0m: Post model outputs failed, status: Model is deploying"
     ]
    }
   ],
   "source": [
    "\n",
    "######################################################################################################\n",
    "# In this section, we set the user authentication, user and app ID, model details, and the URL of \n",
    "# the text we want as an input. Change these strings to run your own example.\n",
    "######################################################################################################\n",
    "\n",
    "# Your PAT (Personal Access Token) can be found in the portal under Authentification\n",
    "PAT = 'f7f840d3e00041d2880a334d1d2e94ed'\n",
    "# Specify the correct user_id/app_id pairings\n",
    "# Since you're making inferences outside your app's scope\n",
    "USER_ID = 'adept'\n",
    "APP_ID = 'fuyu'\n",
    "# Change these to whatever model and text URL you want to use\n",
    "MODEL_ID = 'fuyu-8b'\n",
    "MODEL_VERSION_ID = '97370fc878a24901a50b307462ca90da'\n",
    "RAW_TEXT = 'I love your product very much'\n",
    "# To use a hosted text file, assign the url variable\n",
    "# TEXT_FILE_URL = 'https://samples.clarifai.com/negative_sentence_12.txt'\n",
    "# Or, to use a local text file, assign the url variable\n",
    "# TEXT_FILE_LOCATION = 'YOUR_TEXT_FILE_LOCATION_HERE'\n",
    "\n",
    "############################################################################\n",
    "# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n",
    "############################################################################\n",
    "\n",
    "from clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\n",
    "from clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\n",
    "from clarifai_grpc.grpc.api.status import status_code_pb2\n",
    "\n",
    "channel = ClarifaiChannel.get_grpc_channel()\n",
    "stub = service_pb2_grpc.V2Stub(channel)\n",
    "\n",
    "metadata = (('authorization', 'Key ' + PAT),)\n",
    "\n",
    "userDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n",
    "\n",
    "# To use a local text file, uncomment the following lines\n",
    "# with open(TEXT_FILE_LOCATION, \"rb\") as f:\n",
    "#    file_bytes = f.read()\n",
    "\n",
    "post_model_outputs_response = stub.PostModelOutputs(\n",
    "    service_pb2.PostModelOutputsRequest(\n",
    "        user_app_id=userDataObject,  # The userDataObject is created in the overview and is required when using a PAT\n",
    "        model_id=MODEL_ID,\n",
    "        version_id=MODEL_VERSION_ID,  # This is optional. Defaults to the latest model version\n",
    "        inputs=[\n",
    "            resources_pb2.Input(\n",
    "                data=resources_pb2.Data(\n",
    "                    text=resources_pb2.Text(\n",
    "                        raw=RAW_TEXT\n",
    "                        # url=TEXT_FILE_URL\n",
    "                        # raw=file_bytes\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    metadata=metadata\n",
    ")\n",
    "if post_model_outputs_response.status.code != status_code_pb2.SUCCESS:\n",
    "    print(post_model_outputs_response.status)\n",
    "    raise Exception(\"Post model outputs failed, status: \" + post_model_outputs_response.status.description)\n",
    "\n",
    "# Since we have one input, one output will exist here\n",
    "output = post_model_outputs_response.outputs[0]\n",
    "\n",
    "print(\"Predicted concepts:\")\n",
    "for concept in output.data.concepts:\n",
    "    print(\"%s %.2f\" % (concept.name, concept.value))\n",
    "\n",
    "# Uncomment this line to print the full Response JSON\n",
    "#print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ad6c2e-1218-4ea8-a486-b84639029c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting clarifai_grpc\n",
      "  Using cached clarifai_grpc-10.1.3-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: grpcio>=1.44.0 in c:\\users\\shreshtha\\.venv\\lib\\site-packages (from clarifai_grpc) (1.60.1)\n",
      "Requirement already satisfied: protobuf>=3.20.3 in c:\\users\\shreshtha\\.venv\\lib\\site-packages (from clarifai_grpc) (4.25.2)\n",
      "Collecting googleapis-common-protos>=1.53.0 (from clarifai_grpc)\n",
      "  Using cached googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests>=2.25.1 in c:\\users\\shreshtha\\.venv\\lib\\site-packages (from clarifai_grpc) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shreshtha\\.venv\\lib\\site-packages (from requests>=2.25.1->clarifai_grpc) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shreshtha\\.venv\\lib\\site-packages (from requests>=2.25.1->clarifai_grpc) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shreshtha\\.venv\\lib\\site-packages (from requests>=2.25.1->clarifai_grpc) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shreshtha\\.venv\\lib\\site-packages (from requests>=2.25.1->clarifai_grpc) (2024.2.2)\n",
      "Using cached clarifai_grpc-10.1.3-py3-none-any.whl (225 kB)\n",
      "Using cached googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "Installing collected packages: googleapis-common-protos, clarifai_grpc\n",
      "Successfully installed clarifai_grpc-10.1.3 googleapis-common-protos-1.62.0\n"
     ]
    }
   ],
   "source": [
    "!pip install clarifai_grpc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
