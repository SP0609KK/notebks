{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c86187",
   "metadata": {},
   "source": [
    "### Converting the Excel Workbook to PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69169deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spire.xls import *\n",
    "from spire.xls.common import *\n",
    "# Create a Workbook object\n",
    "\n",
    "workbook = Workbook()\n",
    "# Load an Excel document\n",
    "\n",
    "workbook.LoadFromFile(\"C:/Users/Shreshtha/Downloads/Bartrack Sample.xlsx\")\n",
    "\n",
    "# Iterate through the worksheets in the workbook\n",
    "\n",
    "for sheet in workbook.Worksheets:\n",
    "# Get the PageSetup object\n",
    "\n",
    "    pageSetup = sheet.PageSetup\n",
    "\n",
    "# Set page margins\n",
    "    pageSetup.TopMargin = 0.3\n",
    "\n",
    "    pageSetup.BottomMargin = 0.3\n",
    "\n",
    "    pageSetup.LeftMargin = 0.3\n",
    "\n",
    "    pageSetup.RightMargin = 0.3\n",
    "\n",
    "\n",
    "\n",
    "# Set worksheet to fit to page when converting\n",
    "\n",
    "workbook.ConverterSetting.SheetFitToPage = True\n",
    "\n",
    "\n",
    "\n",
    "# Convert to PDF file\n",
    "\n",
    "workbook.SaveToFile(\"C:/Users/Shreshtha/Downloads/Bartrack-Sample-pdf.pdf\", FileFormat.PDF)\n",
    "\n",
    "workbook.Dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04af585",
   "metadata": {},
   "source": [
    "### Initialising Document AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6492bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/Shreshtha/Downloads/balmy-outcome-412805-e9aa761e058c.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96d7e0c",
   "metadata": {},
   "source": [
    "### Using Document AI's OCR Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3038a0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 page(s) in this document.\n",
      "\n",
      "Page 1 text:\n",
      "Evaluation Warning : The document was created with Spire.XLS for Python\n",
      "period \n",
      "of \n",
      "24\n",
      "ICICI Lombard\n",
      "Max Bupa\n",
      "Apollo Munich\n",
      "Tata AIG\n",
      "Ihealth\n",
      "Heartbeat Gold\n",
      "Optima Restore\n",
      "MediPrime\n",
      "Star Health Comprehensive\n",
      "Basic sum insured\n",
      "10 lacs\n",
      "10 lacs\n",
      "10 lacs\n",
      "10 lacs\n",
      "10 lacs\n",
      "Premium\n",
      "10,643\n",
      "22,696\n",
      "13,607\n",
      "12,205\n",
      "17,483\n",
      "Hosptalization benefits\n",
      "Pre-existing diseases:\n",
      "Pre-existing diseases:\n",
      "Pre-existing diseases: 3\n",
      "Pre-existing diseases:\n",
      "Pre-existing diseases:\n",
      "2 years\n",
      "2 years\n",
      "years\n",
      "4 years\n",
      "4 years\n",
      "Specific illnesses/\n",
      "Specific\n",
      "Specific illnesses/\n",
      "Specific illnesses/\n",
      "Specific illnesses/\n",
      "1 Waiting period\n",
      "treatments: 2 years\n",
      "illnesses/treatments: None\n",
      "treatments: 2 years\n",
      "treatments: 2 years\n",
      "treatments: 2 years\n",
      "No restriction\n",
      "No restriction\n",
      "No restriction\n",
      "No restriction\n",
      "No restriction\n",
      "2 Hospital accomodation\n",
      "/sub-limits\n",
      "/sub-limits\n",
      "/sub-limits\n",
      "/sub-limits\n",
      "/sub-limits\n",
      "60 days if informed of\n",
      "hospitalization 5 days in\n",
      "3 Pre-hospitalization\n",
      "30 days\n",
      "30 days\n",
      "60 days\n",
      "advance, else 30 days\n",
      "30 days\n",
      "90 days if informed of\n",
      "4 Post hospitalization\n",
      "60 days after\n",
      "60 days after\n",
      "hospitalization 5 days in180 daysadvance, else 60 days60 daysOnly in case of shared Only for accompanyingaccomodation.insured child. Rs 500 per day | Rs 750 per day upto 120 daysRs 800 per day for maximum subject to a maximum of Rs with a maximum of 7 daysof 6 days15000per occurrence\n",
      "5 Hospital cash/Daily Cash\n",
      "No\n",
      "Not applicable\n",
      "Actual cost at Network\n",
      "Rs. 1500 per\n",
      "Rs 2000 per\n",
      "Rs 2500 per\n",
      "Rs 3500 per\n",
      "hospital, Rs 2000 perhosptalization otherwise\n",
      "hospitalization\n",
      "hospitalization\n",
      "hospitalization\n",
      "policy period\n",
      "6 Emergency ambulance7 Organ donor expenseCo-payment feature\n",
      "Not covered\n",
      "Covered\n",
      "Covered\n",
      "Covered\n",
      "Not covered\n",
      "8/Annual deductible\n",
      "Not applicable\n",
      "Not applicable\n",
      "Not applicable\n",
      "Not applicable\n",
      "Not applicable101 day care\n",
      "140 day care procedures\n",
      "All day care procedures\n",
      "All day care procedures\n",
      "140 day care procedures\n",
      "covered\n",
      "covered\n",
      "covered\n",
      "covered\n",
      "procedures covered\n",
      "9 Day care procedures10 Domicilliary hospitalization\n",
      "No\n",
      "Yes, upto Rs 50,000\n",
      "Yes\n",
      "Yes\n",
      "No\n",
      "Waiting \n",
      "months. Expenses for 2\n",
      "deliveries,upto Rs 50000 per year\n",
      "Waiting period of 36\n",
      "Husband and wife to be\n",
      "months.\n",
      "Maternity benefits\n",
      "covered under the same\n",
      "Upto Rs 40000 per delivery\n",
      "12 (delivery expenses)\n",
      "Waiting period of 36 months\n",
      "policy\n",
      "None\n",
      "None\n",
      "for 2 deliveries\n",
      "Automatic covered (withoutadditional charge) till theexpiry of policy year inwhich the baby was born.\n",
      "Automatically covered uptoRs 1 lac (without additionalcharge) till the expiry ofpolicy year in which thebaby was born.\n",
      "Vaccination expenses\n",
      "Vaccination expenses upto\n",
      "13 New born baby cover\n",
      "None\n",
      "covered\n",
      "None\n",
      "None\n",
      "Rs 1000 covered\n",
      "Renewal benefits\n",
      "No claim:\n",
      "No Claim:\n",
      "Bonus of 50% of the Basic\n",
      "Additional 10% sum insured\n",
      "Sum Insured\n",
      "No claim: Sum insured\n",
      "In case of claim,\n",
      "enhanced by 10% (bonus)\n",
      "No claim: bonus sum\n",
      "accumulated bonus to be\n",
      "each year.\n",
      "insured at 100% of basic\n",
      "at the time of renewal for Irrespective of whether theevery claim free year.claim was made:In case of a claim,Gift rewards worth 10% ofcumulative additional sum last paid premium orinsured to go down by 50% additional 10% sum insured\n",
      "reduced\n",
      "In case of claim: Cumulative\n",
      "sum insured.\n",
      "by 50% of the basic sum\n",
      "bonus reduced by 10% of\n",
      "In case of claim: bonus sum\n",
      "14 Renewal benefits\n",
      "insured.\n",
      "the basic sum insured\n",
      "insured becomes zero\n",
      "15 Loading on claims\n",
      "ΝΑ\n",
      "NA\n",
      "NA\n",
      "ΝΑ\n",
      "NA\n",
      "Once every four years\n",
      "Once every three\n",
      "16 Health checkup\n",
      "Yes\n",
      "Yes (Annual)\n",
      "No\n",
      "claim free years\n",
      "claim freeyears\n",
      "17 Claim settlement record\n",
      "96.9%\n",
      "82.2%\n",
      "79.0%\n",
      "84.8%\n",
      "69.0%\n",
      "Source: Policy documents for the respective policies (December 2014). For claim settlement data: Mint Mediclaim ratings, Claim settlement ratio calculated as 100%-(%claims repudiated +% claims pending for over six\n",
      "months)\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Page 2 text:\n",
      "Group Name\n",
      "ABC Ltd\n",
      "Group Number\n",
      "Renewal Date\n",
      "123\n",
      "01-01-2024\n",
      "Group State\n",
      "Market\n",
      "No of employees enrolled\n",
      "20\n",
      "Evaluation Warning : The document was created with Spire.XLS for Python\n",
      "CT\n",
      "Large\n",
      "In Network (IN):\n",
      "Copay\n",
      "30/45\n",
      "IN Coinsurance %\n",
      "100/0\n",
      "IN Deductible\n",
      "2500/5000\n",
      "Out of Network (OON):\n",
      "OON Coinsurance %\n",
      "OON Deductible\n",
      "100/0\n",
      "2500/5000\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Page 3 text:\n",
      "Name\n",
      "10-Day Green Smoothie Cleanse\n",
      "11/22/63: A Novel\n",
      "12 Rules for Life: An Antidote to Chaos\n",
      "1984 (Signet Classics)\n",
      "Author\n",
      "JJ Smith\n",
      "Stephen King\n",
      "Jordan B. Peterson\n",
      "George Orwell\n",
      "5,000 Awesome Facts (About Everything!) (National\n",
      "National\n",
      "Geographic Kids) Kids\n",
      "A Dance with Dragons (A Song of Ice and Fire) George R. R. Martin\n",
      "A Game of Thrones / A Clash of Kings / A Storm of Swords / A Feast o\n",
      "A Gentleman in Moscow: A Novel\n",
      "A Higher Loyalty: Truth, Lies, and Leadership\n",
      "A Man Called Ove: A Novel\n",
      "A Man Called Ove: A Novel\n",
      "Amor Towles\n",
      "James Comey\n",
      "Fredrik Backman\n",
      "Fredrik Backman\n",
      "A Patriot's History of the United States: From Columbus's Great D\n",
      "A Stolen Life: A Memoir\n",
      "A Wrinkle in Time (Time Quintet)\n",
      "Jaycee Dugard\n",
      "Madeleine L'Engle\n",
      "Act Like a Lady, Think Like a Man: What Men Really Think Abo\n",
      "Adult Coloring Book Designs: Stress Relief Coloring Book: Garden Designs, Ma\n",
      "Adult Coloring Book: Stress Relieving Animal DesgnsBlue \n",
      "Star Coloring\n",
      "Adult Coloring Book: Stress Relieving Patterns Blue Star Coloring\n",
      "Adult Coloring Books: A Coloring Book for Adults\n",
      "Alexander Hamilton\n",
      "All the Light We Cannot See\n",
      "Featuring Mandalas and H\n",
      "Ron Chernow\n",
      "Anthony Doerr\n",
      "User RatingReviews Price\n",
      "Year\n",
      "Genre\n",
      "4.7\n",
      "17350\n",
      "8\n",
      "2016 Non Fiction\n",
      "4.6\n",
      "2052\n",
      "22\n",
      "2011 Fiction\n",
      "4.7\n",
      "18979\n",
      "15\n",
      "2018 Non Fiction\n",
      "4.7\n",
      "21424\n",
      "6\n",
      "2017 Fiction\n",
      "4.8\n",
      "7665\n",
      "12\n",
      "2019 Non Fiction\n",
      "4.4\n",
      "12643\n",
      "11\n",
      "2011 Fiction\n",
      "Drag\n",
      "19735\n",
      "30\n",
      "2014 Fiction\n",
      "4.7\n",
      "19699\n",
      "15\n",
      "2017 Fiction\n",
      "4.7\n",
      "5983\n",
      "3\n",
      "2018 Non Fiction\n",
      "4.6\n",
      "23848\n",
      "8\n",
      "2016 Fiction\n",
      "4.6\n",
      "23848\n",
      "8\n",
      "2017 Fiction\n",
      "4.6\n",
      "460\n",
      "2\n",
      "2010 Non Fiction\n",
      "4.6\n",
      "4149\n",
      "32\n",
      "2011 Non Fiction\n",
      "4.5\n",
      "5153\n",
      "5\n",
      "2018 Fiction\n",
      "y, an mmitm\n",
      "17\n",
      "2009 Non Fiction\n",
      "4.5\n",
      ",\n",
      "ley Pa\n",
      "4\n",
      "2016 Non Fiction\n",
      "4.6\n",
      "2925\n",
      "6\n",
      "2015 Non Fiction\n",
      "4.4\n",
      "2951\n",
      "6\n",
      "2015 Non Fiction\n",
      "wer4.5\n",
      "mals, a\n",
      "yâ\n",
      "2015 Non Fiction\n",
      "4.8\n",
      "9198\n",
      "13\n",
      "2016 Non Fiction\n",
      "4.6\n",
      "14\n",
      "2014 Fiction\n",
      "36348\n",
      "Evaluation Warning : The document was created with Spire.XLS for Python\n",
      "Allegiant\n",
      "Veronica Roth\n",
      "3.9\n",
      "6310\n",
      "13\n",
      "2013 Fiction\n",
      "American Sniper: The Autobiography of the Most Lethal SnChris Kyle\n",
      "And the Mountains Echoed\n",
      "4.6\n",
      "15921\n",
      "9\n",
      "2015 Non Fiction\n",
      "Khaled Hosseini\n",
      "4.3\n",
      "12159\n",
      "13\n",
      "2013 Fiction\n",
      "Arguing with Idiots: How to Stop Small Minds and Big GoverGlenn Beck\n",
      "4.6\n",
      "798\n",
      "5\n",
      "2009 Non Fiction\n",
      "Astrophysics for People in a Hurry\n",
      "Autobiography of Mark Twain, Vol. 1\n",
      "Neil deGrasse Tyson\n",
      "4.7\n",
      "9374\n",
      "9\n",
      "2017 Non Fiction\n",
      "Mark Twain\n",
      "4.2\n",
      "491\n",
      "14\n",
      "2010 Non Fiction\n",
      "Baby Touch and Feel: Animals\n",
      "DK\n",
      "4.6\n",
      "5360\n",
      "5\n",
      "2015 Non Fiction\n",
      "Balance (Angie's Extreme Stress Menders)\n",
      "Angie Grace\n",
      "4.6\n",
      "1909\n",
      "11\n",
      "2015 Non Fiction\n",
      "Barefoot Contessa Foolproof: Recipes You Can Trust: A CooIna Garten\n",
      "4.8\n",
      "1296\n",
      "24\n",
      "2012 Non Fiction\n",
      "Barefoot Contessa, How Easy Is That?: Fabulous\n",
      "Recipes & E\n",
      "4.7\n",
      "615\n",
      "21\n",
      "2010 Non Fiction\n",
      "Becoming\n",
      "Michelle Obama\n",
      "4.8\n",
      "61133\n",
      "11\n",
      "2018 Non Fiction\n",
      "Becoming\n",
      "Michelle Obama\n",
      "4.8\n",
      "61133\n",
      "11\n",
      "2019 Non Fiction\n",
      "Being Mortal: Medicine and What Matters in the EndAtul \n",
      "Gawande\n",
      "4.8\n",
      "11113\n",
      "15\n",
      "2015 Non Fiction\n",
      "Between the World and Me\n",
      "Ta-Nehisi Coates\n",
      "4.7\n",
      "10070\n",
      "13\n",
      "2015 Non Fiction\n",
      "Between the World and Me\n",
      "Ta-Nehisi Coates\n",
      "4.7\n",
      "10070\n",
      "13\n",
      "2016 Non Fiction\n",
      "Born to Run\n",
      "Bruce Springsteen\n",
      "4.7\n",
      "3729\n",
      "18\n",
      "2016 Non Fiction\n",
      "Breaking Dawn (The Twilight Saga, Book 4)\n",
      "Broke: The Plan to Restore Our Trust, Truth and\n",
      "Brown Bear, Brown Bear, What Do You See?\n",
      "Brown Bear, Brown Bear, What Do You See?\n",
      "Cabin Fever (Diary of a Wimpy Kid, Book 6)\n",
      "Calm the F*ck Down: An Irreverent Adult Coloring Book (IrreveSasha O'Hara\n",
      "Can't Hurt Me: Master Your Mind and Defy the OddsDavid \n",
      "Goggins\n",
      "Stephenie Meyer\n",
      "4.6\n",
      "9769\n",
      "13\n",
      "2009 Fiction\n",
      "TreasureGlenn \n",
      "Beck\n",
      "4.5\n",
      "471\n",
      "8\n",
      "2010 Non Fiction\n",
      "Bill Martin Jr.\n",
      "4.9\n",
      "14344\n",
      "5\n",
      "2017 Fiction\n",
      "Bill Martin Jr.\n",
      "4.9\n",
      "14344\n",
      "5\n",
      "2019 Fiction\n",
      "Jeff Kinney\n",
      "4.8\n",
      "4505\n",
      "0\n",
      "2011 Fiction\n",
      "4.6\n",
      "10369\n",
      "4\n",
      "2016 Non Fiction\n",
      "4.8\n",
      "16244\n",
      "18\n",
      "2019 Non Fiction\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Page 4 text:\n",
      "Evaluation Warning : The document was created with Spire.XLS for Python\n",
      "*******\n",
      "C:\\Users\\Shreshtha\\\n",
      "Downloads\\\n",
      "AmazonBooks.xlsx\n",
      "C:\\Users\\Shreshtha\\\n",
      "Downloads\\\n",
      "honeypr\n",
      "C:\\Users\\Shreshtha\\\n",
      "Downloads\\Order\n",
      "Details.csv\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Page 5 text:\n",
      "Evaluation Warning : The document was created with Spire.XLS for Python\n",
      "C:\\Users\\Shreshtha\\\n",
      "Downloads\\\n",
      "Problem Statement\n",
      "PDF\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Page 6 text:\n",
      "Company Name- ABC Ltd.\n",
      "Source- Google\n",
      "Evaluation Warning : The document was created with Spire.XLS for Python\n",
      "No \n",
      "of \n",
      "Group \n",
      "State\n",
      "CT\n",
      "Group Name\n",
      "ABC Ltd\n",
      "Group Number\n",
      "123\n",
      "Renewal Date\n",
      "01-01-2024\n",
      "20\n",
      "Market\n",
      "Large\n",
      "In Network (IN):\n",
      "30/45\n",
      "CopayIN Coinsurance %\n",
      "100/0\n",
      "IN Deductible\n",
      "2500/5000\n",
      "Out of Network (OON):OON Coinsurance %\n",
      "100/0\n",
      "OON Deductible\n",
      "2500/5000\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Page 7 text:\n",
      "Evaluation Warning : The document was created with Spire.XLS for Python\n",
      "Group Financial Information\n",
      "Link to PDML:\n",
      "http://pdml/\n",
      "Please see Rate Model for available plan combinations\n",
      "Plan Design:\n",
      "KACTOHP63RD\n",
      "In-Network\n",
      "Out-of-Network\n",
      "Office Copay:\n",
      "Modified UCR:Standard\n",
      "PCP:\n",
      "No Charge after Deductible\n",
      "UCR:\n",
      "100% of Medicare\n",
      "Specialist:\n",
      "No Charge after Deductible\n",
      "ER Copay:\n",
      "No Charge after Deductible\n",
      "Hospital Copay\n",
      "Inpatient:\n",
      "No Charge after Deductible\n",
      "Outpatient Hospital Setting:\n",
      "No Charge after Deductible\n",
      "Modified Cost Share:\n",
      "Modified Cost Share:\n",
      "Single Deductible:\n",
      "$2,850\n",
      "Single Deductible:\n",
      "$2,850\n",
      "Family Deductible:\n",
      "$5,700\n",
      "Family Deductible:\n",
      "$5,700\n",
      "Coinsurance:\n",
      "None\n",
      "Coinsurance:\n",
      "30%\n",
      "Single M.O.O.P.\n",
      "$4,000\n",
      "Single M.O.O.P.\n",
      "$5,850\n",
      "Family M.O.O.P.\n",
      "$8,000\n",
      "Family M.O.O.P.\n",
      "$11,700\n",
      "Financial Accumulation Period:\n",
      "Calendar Year\n",
      "Prescription Plan\n",
      "Please see Rate Model for available plan combinations\n",
      "Rx Tracking ID:\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Page 8 text:\n",
      "Spire.XLS for Python\n",
      "e-iceblue Inc. 2002-2024 All rights reserverd\n",
      "Home page\n",
      "https://www.e-iceblue.com\n",
      "Evaluation Warning : The document was created with Spire.XLS for Python\n",
      "Contact US\n",
      "mailto:support@e-iceblue.com\n",
      "Buy Now!\n",
      "https://www.e-iceblue.com/Buy/Spire.XLS-Python.html\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Sequence\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai\n",
    "\n",
    "# Replace the placeholder values with your actual project and processor information\n",
    "project_id = 'balmy-outcome-412805'\n",
    "location = \"us\"  # Format is \"us\" or \"eu\"\n",
    "processor_id = '1c327dd87f42b98b'  # Create processor before running sample\n",
    "processor_version = \"rc\"  # Refer to https://cloud.google.com/document-ai/docs/manage-processor-versions for more information\n",
    "file_path = \"C:/Users/Shreshtha/Downloads/Bartrack-Sample-pdf.pdf\"\n",
    "mime_type = \"application/pdf\"  # Refer to https://cloud.google.com/document-ai/docs/file-types for supported file types\n",
    "\n",
    "def process_document_ocr_sample(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    processor_version: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    ") -> None:\n",
    "    # Optional: Additional configurations for Document OCR Processor.\n",
    "    # For more information: https://cloud.google.com/document-ai/docs/enterprise-document-ocr\n",
    "    process_options = documentai.ProcessOptions(\n",
    "        ocr_config=documentai.OcrConfig(\n",
    "            enable_native_pdf_parsing=True,\n",
    "            enable_image_quality_scores=True,\n",
    "            enable_symbol=True,\n",
    "            # Comment out the premium_features section to disable premium OCR features\n",
    "            # premium_features=documentai.OcrConfig.PremiumFeatures(\n",
    "            #     compute_style_info=True,\n",
    "            #     enable_math_ocr=False,  # Enable to use Math OCR Model\n",
    "            #     enable_selection_mark_detection=True,\n",
    "            # ),\n",
    "        )\n",
    "    )\n",
    "    # Online processing request to Document AI\n",
    "    document = process_document(\n",
    "        project_id,\n",
    "        location,\n",
    "        processor_id,\n",
    "        processor_version,\n",
    "        file_path,\n",
    "        mime_type,\n",
    "        process_options=process_options,\n",
    "    )\n",
    "\n",
    "    print(f\"There are {len(document.pages)} page(s) in this document.\\n\")\n",
    "\n",
    "    for page_num, page in enumerate(document.pages, start=1):\n",
    "        print(f\"Page {page_num} text:\")\n",
    "        print(layout_to_text(page.layout, document.text))\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")  # Adding a separator for better visibility\n",
    "\n",
    "\n",
    "def process_document(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    processor_version: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    "    process_options: Optional[documentai.ProcessOptions] = None,\n",
    ") -> documentai.Document:\n",
    "    # You must set the `api_endpoint` if you use a location other than \"us\".\n",
    "    client = documentai.DocumentProcessorServiceClient(\n",
    "        client_options=ClientOptions(\n",
    "            api_endpoint=f\"{location}-documentai.googleapis.com\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The full resource name of the processor version, e.g.:\n",
    "    # `projects/{project_id}/locations/{location}/processors/{processor_id}/processorVersions/{processor_version_id}`\n",
    "    # You must create a processor before running this sample.\n",
    "    name = client.processor_version_path(\n",
    "        project_id, location, processor_id, processor_version\n",
    "    )\n",
    "\n",
    "    # Read the file into memory\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "    # Configure the process request\n",
    "    request = documentai.ProcessRequest(\n",
    "        name=name,\n",
    "        raw_document=documentai.RawDocument(content=image_content, mime_type=mime_type),\n",
    "        # Only supported for Document OCR processor\n",
    "        process_options=process_options,\n",
    "    )\n",
    "\n",
    "    result = client.process_document(request=request)\n",
    "\n",
    "    # For a full list of `Document` object attributes, reference this page:\n",
    "    # https://cloud.google.com/document-ai/docs/reference/rest/v1/Document\n",
    "    return result.document\n",
    "\n",
    "\n",
    "def layout_to_text(layout: documentai.Document.Page.Layout, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Document AI identifies text in different parts of the document by their\n",
    "    offsets in the entirety of the document\"s text. This function converts\n",
    "    offsets to a string.\n",
    "    \"\"\"\n",
    "    # If a text segment spans several lines, it will\n",
    "    # be stored in different text segments.\n",
    "    return \"\".join(\n",
    "        text[int(segment.start_index) : int(segment.end_index)]\n",
    "        for segment in layout.text_anchor.text_segments\n",
    "    )\n",
    "\n",
    "\n",
    "# Call the function and capture the results\n",
    "process_document_ocr_sample(project_id, location, processor_id, processor_version, file_path, mime_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15b0daf",
   "metadata": {},
   "source": [
    "### Using Document AI's Form Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fc4cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Sequence\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai\n",
    "\n",
    "# Replace these values with your actual configuration\n",
    "project_id = 'balmy-outcome-412805' \n",
    "location = 'us' \n",
    "processor_id = '1c327dd87f42b98b' \n",
    "processor_version = 'rc' \n",
    "local_file_path = \"C:/Users/Shreshtha/Downloads/Bartrack-Sample-pdf.pdf\" \n",
    "mime_type = 'application/pdf'\n",
    "\n",
    "def process_document_form_sample(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    processor_version: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    ") -> documentai.Document:\n",
    "    # Online processing request to Document AI\n",
    "    document = process_document(\n",
    "        project_id, location, processor_id, processor_version, file_path, mime_type\n",
    "    )\n",
    "\n",
    "    # Read the table and form fields output from the processor\n",
    "    # The form processor also contains OCR data. For more information\n",
    "    # on how to parse OCR data please see the OCR sample.\n",
    "\n",
    "    text = document.text\n",
    "\n",
    "    # Read the form fields and tables output from the processor\n",
    "    for page in document.pages:\n",
    "        print(f\"\\n\\n**** Page {page.page_number} ****\")\n",
    "\n",
    "        print(f\"\\nFound {len(page.tables)} table(s):\")\n",
    "        for table in page.tables:\n",
    "            num_columns = len(table.header_rows[0].cells)\n",
    "            num_rows = len(table.body_rows)\n",
    "            print(f\"Table with {num_columns} columns and {num_rows} rows:\")\n",
    "\n",
    "            # Print header rows\n",
    "            print_table_rows(table.header_rows, text)\n",
    "            # Print body rows\n",
    "            print_table_rows(table.body_rows, text)\n",
    "\n",
    "        print(f\"\\nFound {len(page.form_fields)} form field(s):\")\n",
    "        for field in page.form_fields:\n",
    "            name = layout_to_text(field.field_name, text)\n",
    "            value = layout_to_text(field.field_value, text)\n",
    "            print(f\"    * {repr(name.strip())}: {repr(value.strip())}\")\n",
    "\n",
    "    return document\n",
    "\n",
    "def print_table_rows(\n",
    "    table_rows: Sequence[documentai.Document.Page.Table.TableRow], text: str\n",
    ") -> None:\n",
    "    for table_row in table_rows:\n",
    "        row_text = \"\"\n",
    "        for cell in table_row.cells:\n",
    "            cell_text = layout_to_text(cell.layout, text)\n",
    "            row_text += f\"{repr(cell_text.strip())} | \"\n",
    "        print(row_text)\n",
    "\n",
    "def process_document(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    processor_version: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    "    process_options: Optional[documentai.ProcessOptions] = None,\n",
    ") -> documentai.Document:\n",
    "    # You must set the `api_endpoint` if you use a location other than \"us\".\n",
    "    client = documentai.DocumentProcessorServiceClient(\n",
    "        client_options=ClientOptions(\n",
    "            api_endpoint=f\"{location}-documentai.googleapis.com\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The full resource name of the processor version, e.g.:\n",
    "    # `projects/{project_id}/locations/{location}/processors/{processor_id}/processorVersions/{processor_version_id}`\n",
    "    # You must create a processor before running this sample.\n",
    "    name = client.processor_version_path(\n",
    "        project_id, location, processor_id, processor_version\n",
    "    )\n",
    "\n",
    "    # Read the file into memory\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "    # Configure the process request\n",
    "    request = documentai.ProcessRequest(\n",
    "        name=name,\n",
    "        raw_document=documentai.RawDocument(content=image_content, mime_type=mime_type),\n",
    "        # Only supported for Document OCR processor\n",
    "        process_options=process_options,\n",
    "    )\n",
    "\n",
    "    result = client.process_document(request=request)\n",
    "\n",
    "    return result.document\n",
    "\n",
    "def layout_to_text(layout: documentai.Document.Page.Layout, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Document AI identifies text in different parts of the document by their\n",
    "    offsets in the entirety of the document's text. This function converts\n",
    "    offsets to a string.\n",
    "    \"\"\"\n",
    "    # If a text segment spans several lines, it will\n",
    "    # be stored in different text segments.\n",
    "    return \"\".join(\n",
    "        text[int(segment.start_index) : int(segment.end_index)]\n",
    "        for segment in layout.text_anchor.text_segments\n",
    "    )\n",
    "\n",
    "def process_document_form_sample_and_save(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    processor_version: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    "    output_file_path: str\n",
    ") -> documentai.Document:\n",
    "    processed_document = process_document_form_sample(\n",
    "        project_id, location, processor_id, processor_version, file_path, mime_type\n",
    "    )\n",
    "\n",
    "    # Save the output to a text file\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        # Redirect standard output to the file\n",
    "        import sys\n",
    "        original_stdout = sys.stdout\n",
    "        sys.stdout = output_file\n",
    "\n",
    "        try:\n",
    "            # Output the processed document to the file\n",
    "            print_processed_document(processed_document)\n",
    "        finally:\n",
    "            # Restore standard output\n",
    "            sys.stdout = original_stdout\n",
    "\n",
    "    return processed_document\n",
    "\n",
    "def print_processed_document(processed_document: documentai.Document) -> None:\n",
    "    # This function prints the processed document content\n",
    "    # You can customize this function based on your requirements\n",
    "\n",
    "    print(f\"There are {len(processed_document.pages)} page(s) in this document.\")\n",
    "\n",
    "    # Print the content of each page\n",
    "    for page in processed_document.pages:\n",
    "        print(f\"\\n\\n**** Page {page.page_number} ****\")\n",
    "\n",
    "        # Print tables in the document\n",
    "        print(f\"\\nFound {len(page.tables)} table(s):\")\n",
    "        for table in page.tables:\n",
    "            num_columns = len(table.header_rows[0].cells)\n",
    "            num_rows = len(table.body_rows)\n",
    "            print(f\"Table with {num_columns} columns and {num_rows} rows:\")\n",
    "\n",
    "            # Print header rows\n",
    "            print_table_rows(table.header_rows, processed_document.text)\n",
    "            # Print body rows\n",
    "            print_table_rows(table.body_rows, processed_document.text)\n",
    "\n",
    "        # Print form fields in the document\n",
    "        print(f\"\\nFound {len(page.form_fields)} form field(s):\")\n",
    "        for field in page.form_fields:\n",
    "            name = layout_to_text(field.field_name, processed_document.text)\n",
    "            value = layout_to_text(field.field_value, processed_document.text)\n",
    "            print(f\"    * {repr(name.strip())}: {repr(value.strip())}\")\n",
    "\n",
    "def print_table_rows(\n",
    "    table_rows: Sequence[documentai.Document.Page.Table.TableRow], text: str\n",
    ") -> None:\n",
    "    for table_row in table_rows:\n",
    "        row_text = \"\"\n",
    "        for cell in table_row.cells:\n",
    "            cell_text = layout_to_text(cell.layout, text)\n",
    "            # Replace newline characters with spaces\n",
    "            cell_text = cell_text.replace('\\n', ' ')\n",
    "            row_text += f\"{repr(cell_text.strip())} | \"\n",
    "        print(row_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe36c7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**** Page 1 ****\n",
      "\n",
      "Found 2 table(s):\n",
      "Table with 7 columns and 13 rows:\n",
      "'' | 'Basic sum insured' | 'ICICI Lombard Ihealth 10 lacs' | 'Max Bupa Heartbeat Gold 10 lacs' | 'Apollo Munich Optima Restore 10 lacs' | 'Tata AIG MediPrime 10 lacs' | 'Star Health Comprehensive 10 lacs' | \n",
      "'' | 'Premium' | '10,643' | '22,696' | '13,607' | '12,205' | '17,483' | \n",
      "'' | 'Hosptalization benefits' | '' | '' | '' | '' | '' | \n",
      "'' | '' | 'Pre-existing diseases:' | 'Pre-existing diseases:' | 'Pre-existing diseases: 3' | 'Pre-existing diseases:' | 'Pre-existing diseases:' | \n",
      "'1' | 'Waiting period' | '2 years Specific illnesses/ treatments: 2 years No restriction' | '2 years Specific illnesses/treatments: None No restriction' | 'years Specific illnesses/ treatments: 2 years No restriction' | '4 years Specific illnesses/ treatments: 2 years No restriction' | '4 years Specific illnesses/ treatments: 2 years No restriction' | \n",
      "'2' | 'Hospital accomodation' | '/sub-limits' | '/sub-limits' | '/sub-limits' | '/sub-limits 60 days if informed of hospitalization 5 days in' | '/sub-limits' | \n",
      "'3 4' | 'Pre-hospitalization Post hospitalization' | '30 days 60 days after' | '30 days 60 days after' | '60 days 180 days' | 'advance, else 30 days 90 days if informed of hospitalization 5 days inadvance, else 60 days' | '30 days 60 days' | \n",
      "'5 6 7' | 'Hospital cash/Daily Cash Emergency ambulanceOrgan donor expense' | 'No Rs. 1500 per hospitalization Not covered' | 'Not applicable Actual cost at Network hospital, Rs 2000 perhosptalization otherwise Covered' | 'Only in case of shared accomodation.Rs 800 per day for maximum of 6 daysRs 2000 per hospitalization Covered' | 'Only for accompanyinginsured child. Rs 500 per day | subject to a maximum of Rs 15000Rs 2500 per hospitalization Covered' | 'Rs 750 per day upto 120 dayswith a maximum of 7 daysper occurrence Rs 3500 per policy period Not covered' | \n",
      "'89' | 'Co-payment feature /Annual deductible Day care procedures' | 'Not applicable 140 day care procedures covered' | 'Not applicable All day care procedures covered' | 'Not applicable All day care procedures covered' | 'Not applicable 140 day care procedures covered' | 'Not applicable101 day care procedures covered' | \n",
      "'10' | 'Domicilliary hospitalization' | 'No' | 'Yes, upto Rs 50,000' | 'Yes' | 'Yes' | 'No' | \n",
      "'' | 'Evaluation Warning Maternity benefits' | ': The' | 'document was period  of  24 Waiting  months. Expenses for 2 deliveries,upto Rs 50000 per year Husband and wife to be covered under the same' | 'created with' | 'Spire.XLS' | 'for Python Waiting period of 36 months. Upto Rs 40000 per delivery' | \n",
      "'12' | '(delivery expenses)' | 'Waiting period of 36 months' | 'policy' | 'None' | 'None' | 'for 2 deliveries' | \n",
      "'13' | 'New born baby cover Renewal benefits' | 'None' | 'Automatic covered (withoutadditional charge) till theexpiry of policy year inwhich the baby was born. Vaccination expenses covered' | 'None' | 'None' | 'Automatically covered uptoRs 1 lac (without additionalcharge) till the expiry ofpolicy year in which thebaby was born. Vaccination expenses upto Rs 1000 covered' | \n",
      "'' | '' | 'No Claim: Additional 10% sum insured at the time of renewal for every claim free year.' | 'Irrespective of whether theclaim was made:' | 'No claim: Bonus of 50% of the Basic Sum Insured In case of claim, accumulated bonus to be' | 'No claim: Sum insured enhanced by 10% (bonus) each year.' | 'No claim: bonus sum insured at 100% of basic' | \n",
      "Table with 6 columns and 2 rows:\n",
      "'' | 'ICICI Lombard Ihealth' | 'Max Bupa Heartbeat Gold' | 'Apollo Munich Optima Restore' | 'Tata AIG MediPrime' | 'Star Health Comprehensive' | \n",
      "'Basic sum insured' | '10 lacs' | '10 lacs' | '10 lacs' | '10 lacs' | '10 lacs' | \n",
      "'Premium' | '10,643' | '22,696' | '13,607' | '12,205' | '17,483' | \n",
      "\n",
      "Found 2 form field(s):\n",
      "    * 'Premium': '10,643'\n",
      "    * 'Basic sum insured': ''\n",
      "\n",
      "\n",
      "**** Page 2 ****\n",
      "\n",
      "Found 1 table(s):\n",
      "Table with 2 columns and 6 rows:\n",
      "'In Network (IN):' | '' | \n",
      "'Copay' | '30/45' | \n",
      "'IN Coinsurance %' | '100/0' | \n",
      "'IN Deductible' | '2500/5000' | \n",
      "'Out of Network (OON):' | '' | \n",
      "'OON Coinsurance %' | '100/0' | \n",
      "'OON Deductible' | '2500/5000' | \n",
      "\n",
      "Found 8 form field(s):\n",
      "    * 'IN Deductible': '2500/5000'\n",
      "    * 'Copay': '30/45'\n",
      "    * 'Group Name': 'ABC Ltd'\n",
      "    * 'Renewal Date': '01-01-2024'\n",
      "    * 'IN Coinsurance %': '100/0'\n",
      "    * 'OON Deductible': '2500/5000'\n",
      "    * 'No of employees enrolled': '20'\n",
      "    * 'Market\\nEvaluation Warning :': 'The document was created with Spire.XLS Large'\n",
      "\n",
      "\n",
      "**** Page 3 ****\n",
      "\n",
      "Found 3 table(s):\n",
      "Table with 4 columns and 19 rows:\n",
      "'document was created Roth' | 'with 3.9 6310' | 'Spire.XLS 13' | 'for Python 2013 Fiction' | \n",
      "'SnKyle Hosseini' | '4.6 15921 4.3 12159' | '9 13' | '2015 Non Fiction 2013 Fiction' | \n",
      "'GoverBeck' | '4.6 798' | '5' | '2009 Non Fiction' | \n",
      "'deGrasse Tyson' | '4.7 9374' | '9' | '2017 Non Fiction' | \n",
      "'Twain' | '4.2 491' | '14' | '2010 Non Fiction' | \n",
      "'Grace' | '4.6 5360 4.6 1909' | '5 11' | '2015 Non Fiction 2015 Non Fiction' | \n",
      "'Coo' | '4.8 1296' | '24' | '2012 Non Fiction' | \n",
      "'& E' | '4.7 615' | '21' | '2010 Non Fiction' | \n",
      "'Obama' | '4.8 61133' | '11' | '2018 Non Fiction' | \n",
      "'Obama' | '4.8 61133' | '11' | '2019 Non Fiction' | \n",
      "'Gawande' | '4.8 11113' | '15' | '2015 Non Fiction' | \n",
      "'Coates Coates' | '4.7 10070 4.7 10070' | '13 13' | '2015 Non Fiction 2016 Non Fiction' | \n",
      "'Springsteen' | '4.7 3729' | '18' | '2016 Non Fiction' | \n",
      "'Meyer' | '4.6 9769' | '13' | '2009 Fiction' | \n",
      "'Beck' | '4.5 471' | '8' | '2010 Non Fiction' | \n",
      "'Jr.' | '4.9 14344' | '5' | '2017 Fiction' | \n",
      "'Jr.' | '4.9 14344' | '5' | '2019 Fiction' | \n",
      "'Kinney' | '4.8 4505' | '0' | '2011 Fiction' | \n",
      "\"(IrreveO'Hara\" | '4.6 10369' | '4' | '2016 Non Fiction' | \n",
      "'Goggins' | '4.8 16244' | '18' | '2019 Non Fiction' | \n",
      "Table with 5 columns and 21 rows:\n",
      "'Name 10-Day Green Smoothie Cleanse Author JJ Smith' | 'User RatingReviews 4.7' | '17350' | 'Price' | 'Year Genre 8 2016 Non Fiction' | \n",
      "'11/22/63: A Novel Stephen King' | '4.6' | '2052' | '' | '22 2011 Fiction' | \n",
      "'12 Rules for Life: An Antidote to Chaos Jordan B. Peterson' | '4.7' | '18979' | '' | '15 2018 Non Fiction' | \n",
      "'1984 (Signet Classics) George Orwell' | '4.7' | '21424' | '' | '6 2017 Fiction' | \n",
      "'5,000 Awesome Facts (About Everything!) (National National Geographic Kids) Kids' | '4.8' | '7665' | '' | '12 2019 Non Fiction' | \n",
      "'A Dance with Dragons (A Song of Ice and Fire) George R. R. Martin' | '4.4' | '12643' | '' | '11 2011 Fiction' | \n",
      "'A Game of Thrones / A Clash of Kings / A Storm of Swords / A Feast o' | 'Drag' | '19735' | '' | '30 2014 Fiction' | \n",
      "'A Gentleman in Moscow: A Novel Amor Towles' | '4.7' | '19699' | '' | '15 2017 Fiction' | \n",
      "'A Higher Loyalty: Truth, Lies, and Leadership James Comey' | '4.7' | '5983' | '' | '3 2018 Non Fiction' | \n",
      "'A Man Called Ove: A Novel Fredrik Backman' | '4.6' | '23848' | '' | '8 2016 Fiction' | \n",
      "'A Man Called Ove: A Novel Fredrik Backman' | '4.6' | '23848' | '' | '8 2017 Fiction' | \n",
      "\"A Patriot's History of the United States: From Columbus's Great D\" | '4.6' | '460' | '' | '2 2010 Non Fiction' | \n",
      "'A Stolen Life: A Memoir Jaycee Dugard' | '4.6' | '4149' | '' | '32 2011 Non Fiction' | \n",
      "\"A Wrinkle in Time (Time Quintet) Madeleine L'Engle\" | '4.5' | '5153' | '' | '5 2018 Fiction' | \n",
      "'Act Like a Lady, Think Like a Man: What Men Really Think Abo' | 'y, an' | 'mmitm' | '' | '17 2009 Non Fiction' | \n",
      "'Adult Coloring Book Designs: Stress Relief Coloring Book: Garden Designs, Ma' | '4.5 ,' | 'ley Pa' | '' | '4 2016 Non Fiction' | \n",
      "'Adult Coloring Book: Stress Relieving Animal DesgnsBlue  Star Coloring' | '4.6' | '2925' | '' | '6 2015 Non Fiction' | \n",
      "'Adult Coloring Book: Stress Relieving Patterns Blue Star Coloring' | '4.4' | '2951' | '' | '6 2015 Non Fiction' | \n",
      "'Adult Coloring Books: A Coloring Book for Adults Featuring Mandalas and H' | 'wer4.5' | 'mals, a' | '' | 'yâ 2015 Non Fiction' | \n",
      "'Alexander Hamilton Ron Chernow' | '4.8' | '9198' | '' | '13 2016 Non Fiction' | \n",
      "'All the Light We Cannot See Anthony Doerr' | '4.6' | '36348' | '' | '14 2014 Fiction' | \n",
      "'Evaluation Warning : The document was' | 'created with' | '' | 'Spire.XLS' | 'for Python' | \n",
      "Table with 1 columns and 8 rows:\n",
      "'All the Light We Cannot See Anthony Doerr Evaluation Warning : The document was created Allegiant Veronica Roth American Sniper: The Autobiography of the Most Lethal SnChris Kyle And the Mountains Echoed Khaled Hosseini' | \n",
      "\"Arguing with Idiots: How to Stop Small Minds and Big GoverGlenn Beck Astrophysics for People in a Hurry Autobiography of Mark Twain, Vol. 1 Neil deGrasse Tyson Mark Twain Baby Touch and Feel: Animals DK Balance (Angie's Extreme Stress Menders) Angie Grace Barefoot Contessa Foolproof: Recipes You Can Trust: A CooIna Garten\" | \n",
      "'Barefoot Contessa, How Easy Is That?: Fabulous Recipes & E' | \n",
      "'Becoming Michelle Obama Becoming Michelle Obama Being Mortal: Medicine and What Matters in the EndAtul  Gawande' | \n",
      "'Between the World and Me Ta-Nehisi Coates' | \n",
      "'Between the World and Me Ta-Nehisi Coates' | \n",
      "'Born to Run Bruce Springsteen Breaking Dawn (The Twilight Saga, Book 4) Broke: The Plan to Restore Our Trust, Truth and Brown Bear, Brown Bear, What Do You See? Stephenie Meyer TreasureGlenn  Beck Bill Martin Jr.' | \n",
      "\"Brown Bear, Brown Bear, What Do You See? Cabin Fever (Diary of a Wimpy Kid, Book 6) Calm the F*ck Down: An Irreverent Adult Coloring Book (IrreveSasha O'Hara Bill Martin Jr. Jeff Kinney\" | \n",
      "\"Can't Hurt Me: Master Your Mind and Defy the OddsDavid  Goggins\" | \n",
      "\n",
      "Found 0 form field(s):\n",
      "\n",
      "\n",
      "**** Page 4 ****\n",
      "\n",
      "Found 0 table(s):\n",
      "\n",
      "Found 0 form field(s):\n",
      "\n",
      "\n",
      "**** Page 5 ****\n",
      "\n",
      "Found 0 table(s):\n",
      "\n",
      "Found 2 form field(s):\n",
      "    * ': The': 'Evaluation Warning'\n",
      "    * 'C:\\\\Users\\\\Shreshtha\\\\': 'Downloads\\\\\\nProblem Statement'\n",
      "\n",
      "\n",
      "**** Page 6 ****\n",
      "\n",
      "Found 2 table(s):\n",
      "Table with 2 columns and 5 rows:\n",
      "'Evaluation Warning : The document was created Group  State Market In Network (IN): Copay' | 'with Spire.XLS for Python CT Large 30/45' | \n",
      "'IN Coinsurance %' | '100/0' | \n",
      "'IN Deductible' | '2500/5000' | \n",
      "'Out of Network (OON):' | '' | \n",
      "'OON Coinsurance %' | '100/0' | \n",
      "'OON Deductible' | '2500/5000' | \n",
      "Table with 2 columns and 2 rows:\n",
      "'Group Name' | 'ABC Ltd' | \n",
      "'Group Number' | '123' | \n",
      "'Renewal Date' | '01-01-2024' | \n",
      "\n",
      "Found 7 form field(s):\n",
      "    * 'Renewal Date': '01-01-2024'\n",
      "    * 'Copay': '30/45'\n",
      "    * 'ABC Ltd': '123\\n01-01-2024'\n",
      "    * 'Group Name': 'Source- Google\\nABC'\n",
      "    * 'Out of Network (OON):': '30/45\\nCopayIN Coinsurance %\\n100/0\\nIN Deductible\\n2500/5000\\nOON Coinsurance %\\n100/0\\nOON Deductible\\n2500/5000'\n",
      "    * 'OON Coinsurance %\\nOON Deductible': '100/0\\n2500/5000'\n",
      "    * 'Group \\nState': 'Warning : The document was created with Spire.XLS for Python\\nNo \\nof \\nCT\\n20'\n",
      "\n",
      "\n",
      "**** Page 7 ****\n",
      "\n",
      "Found 3 table(s):\n",
      "Table with 2 columns and 4 rows:\n",
      "'Single Deductible:' | '$2,850' | \n",
      "'Family Deductible:' | '$5,700' | \n",
      "'Coinsurance:' | '30%' | \n",
      "'Single M.O.O.P.' | '$5,850' | \n",
      "'Family M.O.O.P.' | '$11,700' | \n",
      "Table with 2 columns and 4 rows:\n",
      "'Single Deductible:' | '$2,850' | \n",
      "'Family Deductible:' | '$5,700' | \n",
      "'Coinsurance:' | 'None' | \n",
      "'Single M.O.O.P.' | '$4,000' | \n",
      "'Family M.O.O.P.' | '$8,000' | \n",
      "Table with 1 columns and 0 rows:\n",
      "'Modified Cost Share:' | \n",
      "\n",
      "Found 20 form field(s):\n",
      "    * 'Specialist:': 'No Charge after Deductible'\n",
      "    * 'Family M.O.O.P.': '$8,000'\n",
      "    * 'Financial Accumulation Period:': 'Calendar Year'\n",
      "    * 'ER Copay:': 'No Charge after Deductible'\n",
      "    * 'Inpatient:': 'No Charge after Deductible'\n",
      "    * 'Family M.O.O.P.': '$11,700'\n",
      "    * 'Single Deductible:': '$2,850'\n",
      "    * 'Outpatient Hospital Setting:': 'No Charge after Deductible'\n",
      "    * 'Coinsurance:': 'None'\n",
      "    * 'Family Deductible:': '$5,700'\n",
      "    * 'Single Deductible:': '$2,850'\n",
      "    * 'UCR:': '100% of Medicare'\n",
      "    * 'Coinsurance:': '30%'\n",
      "    * 'Family Deductible:': '$5,700'\n",
      "    * 'Modified UCR:': 'Standard'\n",
      "    * 'Single M.O.O.P.': '$4,000'\n",
      "    * 'Plan Design:': 'KACTOHP63RD'\n",
      "    * 'Link to PDML:': 'http://pdml/'\n",
      "    * 'PCP:': 'No Charge after Deductible'\n",
      "    * 'Single M.O.O.P.': '$5,850'\n",
      "\n",
      "\n",
      "**** Page 8 ****\n",
      "\n",
      "Found 0 table(s):\n",
      "\n",
      "Found 1 form field(s):\n",
      "    * 'e-iceblue Inc.': '2002-2024 All rights reserverd'\n"
     ]
    }
   ],
   "source": [
    "# Replace these values with your actual configuration\n",
    "project_id = 'balmy-outcome-412805' \n",
    "location = 'us' \n",
    "processor_id = '1c327dd87f42b98b' \n",
    "processor_version = 'rc' \n",
    "local_file_path = \"C:/Users/Shreshtha/Downloads/Bartrack-Sample-pdf.pdf\"  \n",
    "mime_type = 'application/pdf'\n",
    "output_file_path = \"C:/Users/Shreshtha/Downloads/Bartrack-sample.txt\"\n",
    "\n",
    "# Call the main function to process the document and save the output to a file\n",
    "processed_document = process_document_form_sample_and_save(\n",
    "    project_id, location, processor_id, processor_version, local_file_path, mime_type, output_file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e3011f",
   "metadata": {},
   "source": [
    "### Extracting embedded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b4a57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file C:/Users/Shreshtha/Downloads/embedded_files_directory\\extracted_embedded_files\\image1.jpeg: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "Error processing file C:/Users/Shreshtha/Downloads/embedded_files_directory\\extracted_embedded_files\\image2.emf: 'utf-8' codec can't decode byte 0x8e in position 16: invalid start byte\n",
      "Error processing file C:/Users/Shreshtha/Downloads/embedded_files_directory\\extracted_embedded_files\\image3.emf: 'utf-8' codec can't decode byte 0x8e in position 16: invalid start byte\n",
      "Error processing file C:/Users/Shreshtha/Downloads/embedded_files_directory\\extracted_embedded_files\\image4.emf: 'utf-8' codec can't decode byte 0x8e in position 16: invalid start byte\n",
      "Error processing file C:/Users/Shreshtha/Downloads/embedded_files_directory\\extracted_embedded_files\\image5.emf: 'utf-8' codec can't decode byte 0x8e in position 16: invalid start byte\n",
      "Error processing file C:/Users/Shreshtha/Downloads/embedded_files_directory\\extracted_embedded_files\\image6.png: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "Error processing file C:/Users/Shreshtha/Downloads/embedded_files_directory\\extracted_embedded_files\\image7.jpeg: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "Error processing file C:/Users/Shreshtha/Downloads/embedded_files_directory\\extracted_embedded_files\\image8.jpeg: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "Error processing file C:/Users/Shreshtha/Downloads/embedded_files_directory\\extracted_embedded_files\\printerSettings1.bin: 'utf-8' codec can't decode byte 0xdc in position 68: invalid continuation byte\n",
      "Error processing file C:/Users/Shreshtha/Downloads/embedded_files_directory\\extracted_embedded_files\\printerSettings2.bin: 'utf-8' codec can't decode byte 0xdc in position 68: invalid continuation byte\n",
      "Error processing file C:/Users/Shreshtha/Downloads/embedded_files_directory\\extracted_embedded_files\\printerSettings3.bin: 'utf-8' codec can't decode byte 0xdc in position 68: invalid continuation byte\n",
      "Error processing file C:/Users/Shreshtha/Downloads/embedded_files_directory\\extracted_embedded_files\\printerSettings4.bin: 'utf-8' codec can't decode byte 0xdc in position 68: invalid continuation byte\n",
      "Error processing file C:/Users/Shreshtha/Downloads/embedded_files_directory\\extracted_embedded_files\\printerSettings5.bin: 'utf-8' codec can't decode byte 0xdc in position 68: invalid continuation byte\n",
      "Error processing file C:/Users/Shreshtha/Downloads/embedded_files_directory\\extracted_embedded_files\\printerSettings6.bin: 'utf-8' codec can't decode byte 0xdc in position 68: invalid continuation byte\n",
      "Error processing file C:/Users/Shreshtha/Downloads/embedded_files_directory\\extracted_embedded_files\\printerSettings7.bin: 'utf-8' codec can't decode byte 0xdc in position 68: invalid continuation byte\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import mimetypes\n",
    "import io\n",
    "import csv\n",
    "import re\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "from urllib.parse import unquote\n",
    "import shutil\n",
    "\n",
    "def process_embedded_excel_files(input_xlsx_path, output_folder):\n",
    "    def extract_embedded_files(file_path, save_path):\n",
    "        \"\"\"\n",
    "        Extracts arbitrary embedded files from an Excel (xlsx) file and saves them.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        file_path : str,\n",
    "            The path to the xlsx file.\n",
    "\n",
    "        save_path : str,\n",
    "            Directory path to save the extracted files.\n",
    "        \"\"\"\n",
    "            # Create the directory if it doesn't exist\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_file:\n",
    "            # List all files in the archive\n",
    "            all_files = zip_file.namelist()\n",
    "\n",
    "            # Iterate through all files in the archive\n",
    "            for file_info in all_files:\n",
    "                # Extract the file content\n",
    "                file_content = zip_file.read(file_info)\n",
    "\n",
    "                # Save the extracted file to the specified directory\n",
    "                extracted_file_path = os.path.join(save_path, os.path.basename(file_info))\n",
    "                with open(extracted_file_path, 'wb') as f:\n",
    "                    f.write(file_content)\n",
    "\n",
    "    def convert_files_to_txt(input_folder, output_folder):\n",
    "        \"\"\"\n",
    "        Converts each file in the input folder to a plain text file and saves it in the output folder.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        input_folder : str,\n",
    "            The path to the folder containing XML and RELS files.\n",
    "\n",
    "        output_folder : str,\n",
    "            The path to the folder where the converted text files will be saved.\n",
    "        \"\"\"\n",
    "        # Create the output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        for filename in os.listdir(input_folder):\n",
    "            input_file_path = os.path.join(input_folder, filename)\n",
    "            output_file_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "\n",
    "            try:\n",
    "                with open(input_file_path, 'r', encoding='utf-8') as input_file:\n",
    "                    # Read the content of the input file\n",
    "                    file_content = input_file.read()\n",
    "\n",
    "                # Optionally, you can parse XML content if needed\n",
    "                # For example, if the file is in XML format\n",
    "                # tree = ET.fromstring(file_content)\n",
    "                # parsed_content = ET.tostring(tree, encoding='utf-8').decode('utf-8')\n",
    "\n",
    "            # Write the content to the output text file\n",
    "                with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "                    output_file.write(file_content)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {input_file_path}: {e}\")\n",
    "    def extract_text_from_folder(folder_path):\n",
    "        \"\"\"\n",
    "        Extracts text content matching the pattern from text files within a folder.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        folder_path : str,\n",
    "            The path to the folder containing text files.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        matching_paths : list,\n",
    "            A list of concatenated file paths found within the text files.\n",
    "        \"\"\"\n",
    "        matching_paths = []\n",
    "\n",
    "        # Iterate through each file in the folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Check if it's a text file\n",
    "            if os.path.isfile(file_path) and filename.lower().endswith('.txt'):\n",
    "                try:\n",
    "                    # Read the content of the text file\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        file_content = file.read()\n",
    "\n",
    "                    # Use format() to build the string\n",
    "                    matches = re.findall(r'file:///C:\\\\Users\\\\([^\"]+)', file_content)\n",
    "                    matching_paths.extend([\"C:/Users/{}\".format(match.replace('\\\\', '/')) for match in matches])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "        return matching_paths\n",
    "\n",
    "    def fetch_files(matching_paths, output_folder):\n",
    "        # Create the output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        for file_path in matching_paths:\n",
    "            try:\n",
    "                file_name = os.path.basename(unquote(file_path))\n",
    "                shutil.copy(unquote(file_path), os.path.join(output_folder, file_name))\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching file {file_path}: {e}\")\n",
    "\n",
    "    # Create output folders\n",
    "    extracted_folder = os.path.join(output_folder, 'extracted_embedded_files')\n",
    "    converted_folder = os.path.join(output_folder, 'converted_text_files')\n",
    "    fetched_folder = os.path.join(output_folder, 'fetched_excel_files')\n",
    "\n",
    "    # Extract embedded files\n",
    "    extract_embedded_files(input_xlsx_path, extracted_folder)\n",
    "\n",
    "    # Convert files to text\n",
    "    convert_files_to_txt(extracted_folder, converted_folder)\n",
    "\n",
    "    # Extract matching paths from text files\n",
    "    matching_paths = extract_text_from_folder(converted_folder)\n",
    "\n",
    "    # Fetch and copy Excel files\n",
    "    fetch_files(matching_paths, fetched_folder)\n",
    "\n",
    "    # Delete 'converted_text_files' and 'extracted_embedded_files' folders\n",
    "    shutil.rmtree(converted_folder)\n",
    "    shutil.rmtree(extracted_folder)\n",
    "    \n",
    "    \n",
    "\n",
    "# Example usage:\n",
    "input_xlsx_path = \"C:/Users/Shreshtha/Downloads/Bartrack Sample.xlsx\"\n",
    "output_folder = \"C:/Users/Shreshtha/Downloads/embedded_files_directory\"\n",
    "process_embedded_excel_files(input_xlsx_path, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18b6314",
   "metadata": {},
   "source": [
    "### Combining all embedded files and converting to PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3c02332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion successful. PDF saved to C:/Users/Shreshtha/Downloads/Embedded_files_workbook2/Embedded Bartrack Sample Data1.pdf\n"
     ]
    }
   ],
   "source": [
    "from spire.xls import *\n",
    "from spire.xls.common import *\n",
    "import os\n",
    "\n",
    "def combine_and_convert_to_pdf(input_folder, output_directory, output_file_name):\n",
    "    \n",
    "    def combine_excel_files(input_folder, output_directory, output_file_name):\n",
    "        # Create a new workbook\n",
    "        newbook = Workbook()\n",
    "        newbook.Version = ExcelVersion.Version2013\n",
    "        # Clear all default worksheets\n",
    "        newbook.Worksheets.Clear()\n",
    "\n",
    "        # Create a temporary workbook\n",
    "        tempbook = Workbook()\n",
    "\n",
    "        # Iterate through each file in the folder\n",
    "        for file in os.listdir(input_folder):\n",
    "            if file.endswith('.xlsx') or file.endswith('.xls'):\n",
    "                file_path = os.path.join(input_folder, file)\n",
    "\n",
    "                # Load the file into the temporary workbook\n",
    "                tempbook.LoadFromFile(file_path)\n",
    "\n",
    "                # Iterate through each worksheet in the temporary workbook\n",
    "                for sheet_index in range(tempbook.Worksheets.Count):\n",
    "                    # Copy the entire worksheet from the temporary workbook to the new workbook\n",
    "                    new_sheet = newbook.Worksheets.AddCopy(tempbook.Worksheets[sheet_index], WorksheetCopyType.CopyAll)\n",
    "\n",
    "        # Specify the output file path\n",
    "        output_path = os.path.join(output_directory, output_file_name)\n",
    "\n",
    "        # Create the output directory if it doesn't exist\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "        # Save the merged file to the specified directory\n",
    "        newbook.SaveToFile(output_path, ExcelVersion.Version2013)\n",
    "\n",
    "        # Dispose of the workbooks\n",
    "        newbook.Dispose()\n",
    "        tempbook.Dispose()\n",
    "\n",
    "    def convert_excel_to_pdf(input_excel_path, output_pdf_path):\n",
    "        # Create a Workbook object\n",
    "        workbook = Workbook()\n",
    "\n",
    "        try:\n",
    "            # Load an Excel document\n",
    "            workbook.LoadFromFile(input_excel_path)\n",
    "\n",
    "            # Iterate through the worksheets in the workbook\n",
    "            for sheet in workbook.Worksheets:\n",
    "                # Get the PageSetup object\n",
    "                pageSetup = sheet.PageSetup\n",
    "\n",
    "                # Set page margins\n",
    "                pageSetup.TopMargin = 0.3\n",
    "                pageSetup.BottomMargin = 0.3\n",
    "                pageSetup.LeftMargin = 0.3\n",
    "                pageSetup.RightMargin = 0.3\n",
    "\n",
    "            # Set worksheet to fit to page when converting\n",
    "            workbook.ConverterSetting.SheetFitToPage = True\n",
    "\n",
    "            # Convert to PDF file\n",
    "            workbook.SaveToFile(output_pdf_path, FileFormat.PDF)\n",
    "            print(f\"Conversion successful. PDF saved to {output_pdf_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during conversion: {e}\")\n",
    "\n",
    "        finally:\n",
    "            # Dispose of the workbook\n",
    "            workbook.Dispose()\n",
    "\n",
    "    # Combine Excel files\n",
    "    combined_excel_path = os.path.join(output_directory, \"CombinedExcelFiles1.xlsx\")\n",
    "    combine_excel_files(input_folder, output_directory, \"CombinedExcelFiles1.xlsx\")\n",
    "\n",
    "    # Convert combined Excel file to PDF\n",
    "    output_pdf_path = os.path.join(output_directory, output_file_name)\n",
    "    convert_excel_to_pdf(combined_excel_path, output_pdf_path)\n",
    "\n",
    "# Example usage:\n",
    "input_folder_path = \"C:/Users/Shreshtha/Downloads/embedded_files_directory/fetched_excel_files\"\n",
    "output_directory_path = \"C:/Users/Shreshtha/Downloads/Embedded_files_workbook2/\"\n",
    "output_file_name = \"Embedded Bartrack Sample Data1.pdf\"\n",
    "\n",
    "combine_and_convert_to_pdf(input_folder_path, output_directory_path, output_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e1a3c",
   "metadata": {},
   "source": [
    "### Using Form Parser on Combined Embedded Files PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d0688a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Sequence\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai\n",
    "\n",
    "# Replace these values with your actual configuration\n",
    "project_id = 'balmy-outcome-412805' \n",
    "location = 'us' \n",
    "processor_id = '1c327dd87f42b98b' \n",
    "processor_version = 'rc' \n",
    "local_file_path = \"C:/Users/Shreshtha/Downloads/Embedded_files_workbook2/Embedded Bartrack Sample Data1.pdf\"\n",
    "mime_type = 'application/pdf'\n",
    "\n",
    "def process_document_form_sample(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    processor_version: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    ") -> documentai.Document:\n",
    "    # Online processing request to Document AI\n",
    "    document = process_document(\n",
    "        project_id, location, processor_id, processor_version, file_path, mime_type\n",
    "    )\n",
    "\n",
    "    # Read the table and form fields output from the processor\n",
    "    # The form processor also contains OCR data. For more information\n",
    "    # on how to parse OCR data please see the OCR sample.\n",
    "\n",
    "    text = document.text\n",
    "\n",
    "    # Read the form fields and tables output from the processor\n",
    "    for page in document.pages:\n",
    "        print(f\"\\n\\n**** Page {page.page_number} ****\")\n",
    "\n",
    "        print(f\"\\nFound {len(page.tables)} table(s):\")\n",
    "        for table in page.tables:\n",
    "            num_columns = len(table.header_rows[0].cells)\n",
    "            num_rows = len(table.body_rows)\n",
    "            print(f\"Table with {num_columns} columns and {num_rows} rows:\")\n",
    "\n",
    "            # Print header rows\n",
    "            print_table_rows(table.header_rows, text)\n",
    "            # Print body rows\n",
    "            print_table_rows(table.body_rows, text)\n",
    "\n",
    "        print(f\"\\nFound {len(page.form_fields)} form field(s):\")\n",
    "        for field in page.form_fields:\n",
    "            name = layout_to_text(field.field_name, text)\n",
    "            value = layout_to_text(field.field_value, text)\n",
    "            print(f\"    * {repr(name.strip())}: {repr(value.strip())}\")\n",
    "\n",
    "    return document\n",
    "\n",
    "def print_table_rows(\n",
    "    table_rows: Sequence[documentai.Document.Page.Table.TableRow], text: str\n",
    ") -> None:\n",
    "    for table_row in table_rows:\n",
    "        row_text = \"\"\n",
    "        for cell in table_row.cells:\n",
    "            cell_text = layout_to_text(cell.layout, text)\n",
    "            row_text += f\"{repr(cell_text.strip())} | \"\n",
    "        print(row_text)\n",
    "\n",
    "def process_document(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    processor_version: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    "    process_options: Optional[documentai.ProcessOptions] = None,\n",
    ") -> documentai.Document:\n",
    "    # You must set the `api_endpoint` if you use a location other than \"us\".\n",
    "    client = documentai.DocumentProcessorServiceClient(\n",
    "        client_options=ClientOptions(\n",
    "            api_endpoint=f\"{location}-documentai.googleapis.com\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The full resource name of the processor version, e.g.:\n",
    "    # `projects/{project_id}/locations/{location}/processors/{processor_id}/processorVersions/{processor_version_id}`\n",
    "    # You must create a processor before running this sample.\n",
    "    name = client.processor_version_path(\n",
    "        project_id, location, processor_id, processor_version\n",
    "    )\n",
    "\n",
    "    # Read the file into memory\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "    # Configure the process request\n",
    "    request = documentai.ProcessRequest(\n",
    "        name=name,\n",
    "        raw_document=documentai.RawDocument(content=image_content, mime_type=mime_type),\n",
    "        # Only supported for Document OCR processor\n",
    "        process_options=process_options,\n",
    "    )\n",
    "\n",
    "    result = client.process_document(request=request)\n",
    "\n",
    "    return result.document\n",
    "\n",
    "def layout_to_text(layout: documentai.Document.Page.Layout, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Document AI identifies text in different parts of the document by their\n",
    "    offsets in the entirety of the document's text. This function converts\n",
    "    offsets to a string.\n",
    "    \"\"\"\n",
    "    # If a text segment spans several lines, it will\n",
    "    # be stored in different text segments.\n",
    "    return \"\".join(\n",
    "        text[int(segment.start_index) : int(segment.end_index)]\n",
    "        for segment in layout.text_anchor.text_segments\n",
    "    )\n",
    "\n",
    "def process_document_form_sample_and_save(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    processor_version: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    "    output_file_path: str\n",
    ") -> documentai.Document:\n",
    "    processed_document = process_document_form_sample(\n",
    "        project_id, location, processor_id, processor_version, file_path, mime_type\n",
    "    )\n",
    "\n",
    "    # Save the output to a text file\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        # Redirect standard output to the file\n",
    "        import sys\n",
    "        original_stdout = sys.stdout\n",
    "        sys.stdout = output_file\n",
    "\n",
    "        try:\n",
    "            # Output the processed document to the file\n",
    "            print_processed_document(processed_document)\n",
    "        finally:\n",
    "            # Restore standard output\n",
    "            sys.stdout = original_stdout\n",
    "\n",
    "    return processed_document\n",
    "\n",
    "def print_processed_document(processed_document: documentai.Document) -> None:\n",
    "    # This function prints the processed document content\n",
    "    # You can customize this function based on your requirements\n",
    "\n",
    "    print(f\"There are {len(processed_document.pages)} page(s) in this document.\")\n",
    "\n",
    "    # Print the content of each page\n",
    "    for page in processed_document.pages:\n",
    "        print(f\"\\n\\n**** Page {page.page_number} ****\")\n",
    "\n",
    "        # Print tables in the document\n",
    "        print(f\"\\nFound {len(page.tables)} table(s):\")\n",
    "        for table in page.tables:\n",
    "            num_columns = len(table.header_rows[0].cells)\n",
    "            num_rows = len(table.body_rows)\n",
    "            print(f\"Table with {num_columns} columns and {num_rows} rows:\")\n",
    "\n",
    "            # Print header rows\n",
    "            print_table_rows(table.header_rows, processed_document.text)\n",
    "            # Print body rows\n",
    "            print_table_rows(table.body_rows, processed_document.text)\n",
    "\n",
    "        # Print form fields in the document\n",
    "        print(f\"\\nFound {len(page.form_fields)} form field(s):\")\n",
    "        for field in page.form_fields:\n",
    "            name = layout_to_text(field.field_name, processed_document.text)\n",
    "            value = layout_to_text(field.field_value, processed_document.text)\n",
    "            print(f\"    * {repr(name.strip())}: {repr(value.strip())}\")\n",
    "\n",
    "def print_table_rows(\n",
    "    table_rows: Sequence[documentai.Document.Page.Table.TableRow], text: str\n",
    ") -> None:\n",
    "    for table_row in table_rows:\n",
    "        row_text = \"\"\n",
    "        for cell in table_row.cells:\n",
    "            cell_text = layout_to_text(cell.layout, text)\n",
    "            # Replace newline characters with spaces\n",
    "            cell_text = cell_text.replace('\\n', ' ')\n",
    "            row_text += f\"{repr(cell_text.strip())} | \"\n",
    "        print(row_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30748526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**** Page 1 ****\n",
      "\n",
      "Found 1 table(s):\n",
      "Table with 2 columns and 44 rows:\n",
      "\"Name Author User 10-Day Green Smoothie C 11/22/63: A NovelStephen King 12 Rules for Life: An Antidote to Ch 1984 (Signet Classics) George Orwell 5,000 Awesome Facts (About Every A Dance with Dragons (A Song A Game of Thrones / A Clash of King A Gentleman in Moscow: A NovAmor Towles of Ice A Higher Loyalty: Truth, Lies, an A Man Called Ove: A NovelFredrik  Backman A Man Called Ove: A NovelFredrik  Backman A Patriot's History of the United St A Stolen Life: A MemoirJaycee  Dugard A Wrinkle in Time (Time Quintet)Madeleine  L'Engle Act Like a Lady, Think Like a Ma Adult Coloring Book Designs: Stress Adult Coloring Book: Stress Relievin\" | 'Rating Reviews Price Year 4.7 17350 8 Genre 2016 Non Fiction 4.6 2052 22 2011 Fiction 4.7 18979 15 2018 Non Fiction 4.7 21424 6 2017 Fiction nal G Kids)7665 12 2019 Non Fiction 4.4 12643 11 2011 Fiction f Sw ast of e 30 w 2014 Fiction 4.7 19699 15 2017 Fiction 4.7 5983 3 2018 Non Fiction 4.6 23848 8 2016 Fiction 4.6 23848 8 2017 Fiction umb scov n 2010 Non Fiction 4.6 4149 32 2011 Non Fiction 4.5 5153 5 2018 Fiction 4.6ly  T Love, nti 2009 Non Fiction 4.5 Desig ni 2016isley  PatternsNon  Fiction gns 4.6 2925 6 2015 Non Fiction' | \n",
      "'Adult Coloring Book: Stress Relievin Adult Coloring Books: A Coloring Bo Alexander HamiltonRon Chernow All the Light We Cannot SeeAnthony  Doerr All the Light We Cannot SeeAnthony  Doerr Allegiant Veronica Roth' | '4.4 2951 6 2015 Non Fiction Fea alas a ed nimals and Paisley 4.8 9198 13 2016 Non Fiction 4.6 36348 14 2014 Fiction 4.6 36348 14 2015 Fiction 3.9 6310 13 2013 Fiction' | \n",
      "'American Sniper: The Autob And the Mountains EchoedKhaled  Hosseini' | 'Let n U.S. 9 2015 Non Fiction 4.3 12159 13 2013 Fiction' | \n",
      "'Arguing with Idiots: How to S Astrophysics for People deGrassein a  Hurry Tys' | 'd Big 798 5 2009 Non Fiction 4.7 9374 9 2017 Non Fiction' | \n",
      "\"Autobiography of Mark TwainMark Twain Baby Touch and FeelDK Balance (Angie's Extreme StreAngie Grace Barefoot Contessa Foolproof Barefoot Contessa, How Easy\" | '4.2 491 14 2010 Non Fiction 4.6 5360 5 2015 Non Fiction 4.6 1909 11 2015 Non Fiction ust: 1296 24 2012 Non Fiction Reci ps 615 21 2010 Non Fiction' | \n",
      "'Becoming Michelle Obama Becoming Michelle Obama' | '4.8 61133 11 2018 Non Fiction 4.8 61133 11 2019 Non Fiction' | \n",
      "\"Being Mortal: Medicine and Wh Between the World and MeTa-Nehisi  Coates Between the World and MeTa-Nehisi  Coates Born to Run Bruce Springsteen Breaking Dawn (The Twilight Saga,Stephenie Meyer Broke: The Plan to Restore O Brown Bear, Brown Bear, What Brown Bear, Brown Bear, What Cabin Fever (Diary of a WimpJeff Kinney Calm the F*ck Down: An Irreve Can't Hurt Me: Master Your GogginsMin Capital in the Twenty First CenturThomas Piketty\" | 'End 11113 15 2015 Non Fiction 4.7 10070 13 2015 Non Fiction 4.7 10070 13 2016 Non Fiction 4.7 3729 18 2016 Non Fiction 4.6 9769 13 2009 Fiction rea 471 8 2010 Non Fiction 4.9 14344 5 2017 Fiction 4.9 14344 5 2019 Fiction 4.8 4505 0 2011 Fiction g Bo ent Boo 4 2016 Non Fiction dds 16244 18 2019 Non Fiction 4.5 2884 28 2014 Non Fiction' | \n",
      "'Catching Fire (The Hunger GamesSuzanne Collins' | '4.7 22614 11 2010 Fiction' | \n",
      "'Catching Fire (The Hunger GamesSuzanne Collins Catching Fire (The Hunger GamesSuzanne Collins' | '4.7 22614 11 2011 Fiction 4.7 22614 11 2012 Fiction' | \n",
      "'Cravings: Recipes for All the Foo Crazy Love: Overwhelmed by a Crazy Love: Overwhelmed by a Crazy Love: Overwhelmed by a Crazy Rich Asians (Crazy RichKevin Kwan' | '4.7t: A 4761 16 2016 Non Fiction 4.7 1542 14 2009 Non Fiction 4.7 1542 14 2010 Non Fiction 4.7 1542 14 2011 Non Fiction 4.3 6143 8 2018 Fiction' | \n",
      "'Creative Haven Creative Marjorie Cats SarnatColo Creative Haven Owls Coloring Boo' | 't Co 4022 4 2015 Non Fiction ng)4.8 3871 5 2015 Non Fiction' | \n",
      "'Cutting for Stone Abraham Verghes Cutting for Stone Abraham Verghes Daring Greatly: How BreneÌ\\uf081the  Courage t David and Goliath: Underdogs, Misf Dead And Gone: A Sookie Stackho' | '4.6 4866 11 2010 Fiction 4.6 4866 11 2011 Fiction e Tr e Way 10Pa 2013 Non Fiction rt of 4642 13 2013 Non Fiction kie True B 4 2009 Fiction' | \n",
      "'Dead in the Family (Sookie Stackh' | 'd, B 1924 8 2010 Fiction' | \n",
      "'Dead Reckoning (Sookie Stackhou' | 'Boo 2094 4 2011 Fiction' | \n",
      "'Dear Zoo: A Lift-the-Flap BookRod Campbell Dear Zoo: A Lift-the-Flap BookRod Campbell Dear Zoo: A Lift-the-Flap BookRod Campbell Dear Zoo: A Lift-the-Flap BookRod Campbell Decision Points George W. Bush' | '4.8 10922 5 2015 Fiction 4.8 10922 5 2016 Fiction 4.8 10922 5 2017 Fiction 4.8 10922 5 2018 Fiction 4.6 2137 17 2010 Non Fiction' | \n",
      "'Delivering Happiness: A Path Diagnostic and Statistical Manual of Diagnostic and Statistical Manual of Diary of a Wimpy Kid: Hard L Diary of a Wimpy Kid: The La Diary of a Wimpy Kid: The Lo Difficult Riddles For Smart Kids: 3 Divergent Veronica Roth Divergent Veronica Roth Divergent / Insurgent Veronica Roth Divine Soul Mind Body Healing Doctor Sleep: A Novel Stephen King Dog Days (Diary of Jeffa  Wimpy' | 'and 1651 15 2010 Non Fiction n4.5 n: DSM 105 2013 Non Fiction n4.5 n: DSM 105 2014 Non Fiction 4.8 6812 0 2013 Fiction 4.8 3837 15 2009 Fiction 4.8 6540 22 2014 Fiction les asers ve5 2019 Kids)Non  Fiction 4.6 27098 15 2013 Fiction 4.6 27098 15 2014 Fiction 4.5 17684 6 2014 Fiction Sys e W H ther Earth, and Al 4.7 15845 13 2013 Fiction 4.8 3181 12 2009 Fiction' | \n",
      "'Dog Man and Cat Kid: PilkeyFrom Dog Man: A Tale of Two Kitt' | '4.9 Dog M 6 2018 Fiction 4.9 erpan 8 2017 Fiction' | \n",
      "'Dog Man: Brawl of the Wild: Dog Man: Brawl of the Wild: Dog Man: Fetch-22: From th Dog Man: For Whom the Ba Dog Man: Lord of the Fleas:' | 'Cap ants ( 4 2018 Fiction Cap ants ( 4 2019 Fiction Und og Man 8 2019 Fiction ator Under # 2019 Fiction Cap ants (D 6 2018 Fiction' | \n",
      "'Double Down (Diary of a WimJeff Kinney Dover Creative Haven Marty Art NobleNouv' | '4.8 5118 20 2016 Fiction ns C k (Crea ri 2015 Non Fiction' | \n",
      "'Drive: The Surprising Truth Abou Eat This Not That Supermarket Su!  Eat This, Not That! Thousands of S Eat to Live: The Amazing Nutrient-R Eat to Live: The Amazing Nutrient-R' | '4.5 2525 16 2010 Non Fiction he N 720 1 2009 Non Fiction aps 4.3 You 14 2009 Non Fiction or 4.5 F ained v 2011 Non Fiction or F ained v 2012 Non Fiction' | \n",
      "'Eclipse (Twilight Sagas) Stephenie Meyer Eclipse (Twilight) Stephenie Meyer' | '4.7 5505 7 2009 Fiction 4.7 5505 18 2009 Fiction' | \n",
      "'Educated: A MemoirTara  Westover Educated: A MemoirTara  Westover Enchanted Forest: An Inky Quest a Fahrenheit 451 Ray Bradbury Fahrenheit 451 Ray Bradbury Fantastic Beasts andJ.K.  WhereRowling to Fear: Trump in the White HouseBob Woodward Fifty Shades DarkerE L James Fifty Shades Freed: Book Th Fifty Shades of Grey: Book One of the Fifty Shades of Grey: Book One of the Evaluation Warning : The' | '4.7 28729 15 2018 Non Fiction 4.7 28729 15 2019 Non Fiction ok ( ks, 5413M Me strated Floral Prin 4.6 10721 8 2016 Fiction 4.6 10721 8 2018 Fiction rigin y (Ha 15 2016 Fiction 4.4 6042 2 2018 Non Fiction 4.4 23631 7 2012 Fiction s Tr Fifty Shades Trilogy (Fifty Shades of Grey Series) 14 Fifty Shades Trilogy (Fifty Shades of Grey Series) n) 2012 Fiction 2012 Fiction 2013 Fiction document was created with Spire.XLS for Python Shades ) (E' | \n",
      "'Fifty Shades Trilogy (Fifty Sh Fire and Fury: Inside the TrumpMichael Wolff' | 'had 13964Fifty S 32 2012 Fiction 4.2 13677 6 2018 Non Fiction' | \n",
      "'First 100 Words Roger Priddy First 100 Words Roger Priddy' | '4.7 17323 4 2014 Non Fiction 4.7 17323 4 2015 Non Fiction' | \n",
      "'First 100 Words Roger Priddy First 100 Words Roger Priddy' | '4.7 17323 4 2016 Non Fiction 4.7 17323 4 2017 Non Fiction' | \n",
      "\"First 100 Words Roger Priddy Food Rules: An Eater's ManualMichael Pollan Frozen (Little Golden Book)RH Disney Game Change: Obama and the Cli Game of Thrones GeorgeBoxed  Set:R.R.  A Gam\" | '4.7 17323 4 2018 Non Fiction 4.4 1555 9 2010 Non Fiction 4.7 3642 0 2014 Fiction and e Rac 9 2010 Non Fiction 4.6 /A Sto 5 F ws 2011 Fiction' | \n",
      "'Game of Thrones GeorgeBoxed  Set:R.R.  A Gam Game of Thrones GeorgeBoxed  Set:R.R.  A Gam' | '4.6 /A Sto 5 F ws 2012 Fiction 4.6 /A Sto 5 F ws 2013 Fiction' | \n",
      "\"George Washington's Sacred Fire George Washington's Secret Six: Giraffes Can't DanceGiles Andreae\" | '4.5 408 20 2010 Non Fiction at Sa erican 16 2013 Non Fiction 4.8 14038 4 2015 Fiction' | \n",
      "\"Giraffes Can't DanceGiles Andreae Giraffes Can't DanceGiles Andreae\" | '4.8 14038 4 2016 Fiction 4.8 14038 4 2017 Fiction' | \n",
      "\"Giraffes Can't DanceGiles Andreae Giraffes Can't DanceGiles Andreae Girl, Stop Apologizing: A Sham Girl, Wash Your Face: Stop Beli\" | '4.8 14038 4 2018 Fiction 4.8 14038 4 2019 Fiction brac eving 12 2019 Non Fiction ut W e So Yo Wh 2018 Non Fiction' | \n",
      "\"Girl, Wash Your Face: Stop Beli Glenn Beck's Common Sense\" | 'ut W e So Yo Wh 2019 Non Fiction n Ou Gove ed 2009 Non Fiction' | \n",
      "'Go Set a Watchman: A NovelHarper Lee Go the F**k to SleepAdam Mansbach Going Rogue: An American LiSarah Palin Gone Girl Gillian Flynn Gone Girl Gillian Flynn Gone Girl Gillian Flynn Good Days Start With Gratitude: A 5' | '3.6 14982 19 2015 Fiction 4.8 9568 9 2011 Fiction 4.6 1636 6 2009 Non Fiction 4 57271 10 2012 Fiction 4 57271 10 2013 Fiction 4 57271 9 2014 Fiction e To An Atti e 2019 Non Fiction' | \n",
      "'Good to Great: Why Some C Good to Great: Why Some C' | \"Leap Don' 14 2009 Non Fiction Leap Don' 14 2010 Non Fiction\" | \n",
      "'Good to Great: Why Some C' | \"Leap Don' 14 2011 Non Fiction\" | \n",
      "'Good to Great: Why Some C Goodnight Moon Margaret Wise Br Goodnight Moon Margaret Wise Br Goodnight Moon Margaret Wise Br' | \"Leap Don' 14 2012 Non Fiction 4.8 8837 5 2017 Fiction 4.8 8837 5 2018 Fiction 4.8 8837 5 2019 Fiction\" | \n",
      "'Goodnight, Goodnight Construction Goodnight, Goodnight Construction' | 'ver4.9 ddlers ks 2012 Fiction ver 4.9 ddlers ks 2013 Fiction' | \n",
      "'Grain Brain: The Surprising Truth ab Grey: Fifty Shades of Grey a Guts Raina Telgemeier Hamilton: The RevolutionLin- Manuel Miran Happy, Happy, Happy: My Life an Harry Potter and the Chambe Harry Potter and the Cursed C' | 'arbs -Your ille 2014 Non Fiction fty S 25624rey Ser 14 2015 Fiction 4.8 5476 7 2019 Non Fiction 4.9 5867 54 2016 Non Fiction Duc 4148 11 2013 Non Fiction stra (Harry 2) 30 2016 Fiction cia l Editio 12 2016 Fiction' | \n",
      "'Harry Potter and the Goblet of Harry Potter and the Prisoner' | '4.9 Potte 18 2019 Fiction ustr (Harry 3) 30 2017 Fiction' | \n",
      "'Harry Potter and the Sorcerer Harry Potter Coloring BookScholastic Harry Potter Paperback Box Se Have a Little Faith: A True StoryMitch Albom Heaven is for Rea: ToddA  Little BurpoBo Heaven is for Rea: ToddA  Little BurpoBo' | 'ated arry Po 22 2016 Fiction 4.7 3564 9 2015 Non Fiction 4.8 13471 52 2016 Fiction 4.8 1930 4 2009 Non Fiction y of Heaven 10 2011 Non Fiction y of Heaven 10 2012 Non Fiction' | \n",
      "'Hillbilly Elegy: A Memoir of a Hillbilly Elegy: A Memoir of a Homebody: A Guide to Creating How to Win Friends & InfluenceDale Carnegie How to Win Friends & InfluenceDale Carnegie How to Win Friends & InfluenceDale Carnegie How to Win Friends & InfluenceDale Carnegie' | 'n Cr 15526 14 2016 Non Fiction n Cr 15526 14 2017 Non Fiction 4.8 3776 22 2018 Non Fiction 4.7 25001 11 2014 Non Fiction 4.7 25001 11 2015 Non Fiction 4.7 25001 11 2016 Non Fiction 4.7 25001 11 2017 Non Fiction' | \n",
      "'How to Win Friends & InfluenceDale Carnegie Howard Stern Comes AgainHoward  Stern' | '4.7 25001 11 2018 Non Fiction 4.3 5272 16 2019 Non Fiction' | \n",
      "'Humans of New York Bandon Stanton Humans of New York Bandon Stanton Humans of New York : StoriesBrandon  Stanton' | '4.8 3490 15 2013 Non Fiction 4.8 3490 15 2014 Non Fiction 4.9 2812 17 2015 Non Fiction' | \n",
      "'Hyperbole and a Half: Unfort I Am Confident, Brave & Beautifu' | 'wed chani an17 gs That Happened ok fo 9737 7 2019 Non Fiction' | \n",
      "'I, Alex Cross James Patterson If Animals Kissed Good NightAnn Whitford Pau If Animals Kissed Good NightAnn Whitford  Pau If I Stay Gayle Forman In the Garden of Beasts: Love' | '4.6 1320 7 2009 Fiction 4.8 16643 4 2017 Fiction 4.8 16643 4 2019 Fiction 4.3 7153 9 2014 Fiction erica Hitler 21 2011 Non Fiction' | \n",
      "'Inferno Dan Brown' | '4.1 29651 14 2013 Fiction' | \n",
      "\n",
      "Found 0 form field(s):\n",
      "\n",
      "\n",
      "**** Page 2 ****\n",
      "\n",
      "Found 0 table(s):\n",
      "\n",
      "Found 2 form field(s):\n",
      "    * 'e-iceblue Inc.': '2002-2024 All rights reserverd'\n",
      "    * 'Buy Now!': 'https://www.e-iceblue.com/Buy/Spire.XLS-Python.html'\n"
     ]
    }
   ],
   "source": [
    "# Replace these values with your actual configuration\n",
    "project_id = 'balmy-outcome-412805' \n",
    "location = 'us' \n",
    "processor_id = '1c327dd87f42b98b' \n",
    "processor_version = 'rc' \n",
    "local_file_path = \"C:/Users/Shreshtha/Downloads/Embedded_files_workbook2/Embedded Bartrack Sample Data1.pdf\"  \n",
    "mime_type = 'application/pdf'\n",
    "output_file_path = \"C:/Users/Shreshtha/Downloads/embedded-bartrack-sample.txt\"\n",
    "\n",
    "# Call the main function to process the document and save the output to a file\n",
    "processed_document = process_document_form_sample_and_save(\n",
    "    project_id, location, processor_id, processor_version, local_file_path, mime_type, output_file_path\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
