{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b4ea6bd",
   "metadata": {},
   "source": [
    "### 1. Extract the images from the excel workbook and store in a folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ffccd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil # Used to copy the images to new path and to remove the temp directory\n",
    "import pathlib # Helps in making the paths consistent and helps to join different directories or folders for transferring data\n",
    "import zipfile # Works when excel files are zipped\n",
    "import os # Helps to interact with the operating system\n",
    "\n",
    "def extract_images_from_excel(path, output_folder_name='extracted_images_again'):\n",
    "    \"\"\"\n",
    "    Extracts images from an Excel file and stores them in a single folder.\n",
    "\n",
    "    Args:\n",
    "        path (pathlib.Path or str): Excel file path.\n",
    "        output_folder_name (str): Name of the folder to store the extracted images.\n",
    "            Defaults to 'extracted_images_again'.\n",
    "\n",
    "    Returns:\n",
    "        new_paths (list[pathlib.Path]): List of paths to extracted images.\n",
    "    \"\"\"\n",
    "    # Convert path to pathlib.Path if it's a string\n",
    "    if isinstance(path, str):\n",
    "        path = pathlib.Path(path)\n",
    "\n",
    "    # Check if the file has the '.xlsx' extension\n",
    "    if path.suffix != '.xlsx':\n",
    "        raise ValueError('Path must be an xlsx file')\n",
    "\n",
    "    # Extract the filename (excluding the extension) using .stem\n",
    "    name = path.stem\n",
    "\n",
    "    # Create a new folder for the extracted images\n",
    "    output_folder = path.parent / output_folder_name\n",
    "    output_folder.mkdir(exist_ok=True)  # Create folder if it doesn't exist\n",
    "\n",
    "    # Create a temporary directory for unzipping the Excel file\n",
    "    temp_dir = path.parent / 'temp'\n",
    "    temp_dir.mkdir(exist_ok=True)  # Create folder if it doesn't exist\n",
    "\n",
    "    try:\n",
    "        # Unzip the Excel file into the temporary directory\n",
    "        with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(temp_dir)\n",
    "\n",
    "        # Locate the 'media' directory within the unzipped content\n",
    "        media_dir = temp_dir / 'xl' / 'media'\n",
    "\n",
    "        image_index = 0  # Initialize an index for the images\n",
    "        new_paths = []  # List to store the paths of the extracted images\n",
    "\n",
    "        # Iterate through the files in the 'media' directory\n",
    "        for root, dirs, files in os.walk(media_dir):\n",
    "            for file in files:\n",
    "                image_index += 1  # Increment the image index for each image found\n",
    "\n",
    "                # Construct paths for the original image and the new destination\n",
    "                image_path = pathlib.Path(root) / file\n",
    "                new_path = output_folder / f'{name}-{str(image_index)}.png'\n",
    "\n",
    "                # Copy the image to the output folder with a new name\n",
    "                shutil.copy(image_path, new_path)\n",
    "\n",
    "                # Store the new path in the list\n",
    "                new_paths.append(new_path)\n",
    "\n",
    "    finally:\n",
    "        # Cleanup: Remove the temporary directory\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "    # Return the list of paths to the extracted images\n",
    "    return new_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fced489",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file_path = \"C:/Users/Shreshtha/Downloads/Project UHC/Trial 2.xlsx\"\n",
    "extracted_image_paths = extract_images_from_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d90e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing the images\n",
    "images_directory = \"C:/Users/Shreshtha/Downloads/Project UHC/extracted_images_again\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0cbf1a",
   "metadata": {},
   "source": [
    "### 2. Use K-Means image clustering to group the images which look similar and create subfolders for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a08fafe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreshtha\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def resize_image(image, target_size=(300, 300)):\n",
    "    try:\n",
    "        if image is not None and image.size != 0:\n",
    "            return cv2.resize(image, target_size)\n",
    "        else:\n",
    "            return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error resizing image: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_features(image_path, target_size=(300, 300)):\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        resized_image = resize_image(image, target_size)\n",
    "\n",
    "        if resized_image is not None:\n",
    "            # Convert the image to grayscale\n",
    "            gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Flatten the 2D array into a 1D array\n",
    "            flattened = gray.flatten()\n",
    "\n",
    "            return flattened\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features: {e}\")\n",
    "        return None\n",
    "\n",
    "def group_similar_images_kmeans(input_folder, output_folder, num_clusters=5):\n",
    "    try:\n",
    "        image_files = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "        feature_vectors = []\n",
    "\n",
    "        for img_file in image_files:\n",
    "            features = extract_features(os.path.join(input_folder, img_file))\n",
    "            if features is not None:\n",
    "                feature_vectors.append(features)\n",
    "\n",
    "        if feature_vectors:\n",
    "            feature_vectors = np.array(feature_vectors)\n",
    "\n",
    "            # Apply k-means clustering\n",
    "            kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "            cluster_labels = kmeans.fit_predict(feature_vectors)\n",
    "\n",
    "            # Create output folders for each cluster\n",
    "            for i in range(num_clusters):\n",
    "                cluster_folder = os.path.join(output_folder, f\"Cluster_{i + 1}\")\n",
    "                os.makedirs(cluster_folder, exist_ok=True)\n",
    "\n",
    "            # Move images to their respective cluster folders\n",
    "            for img_file, label in zip(image_files, cluster_labels):\n",
    "                cluster_folder = os.path.join(output_folder, f\"Cluster_{label + 1}\")\n",
    "                shutil.move(os.path.join(input_folder, img_file), cluster_folder)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error grouping similar images: {e}\")\n",
    "\n",
    "# Specify your input and output folder paths\n",
    "input_folder_path = \"C:/Users/Shreshtha/Downloads/Project UHC/extracted_images_again\"\n",
    "output_folder_path = \"C:/Users/Shreshtha/Downloads/Project UHC/Output Folder 2\"\n",
    "\n",
    "# Call the function with a specified number of clusters\n",
    "group_similar_images_kmeans(input_folder_path, output_folder_path, num_clusters=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836317fd",
   "metadata": {},
   "source": [
    "### 3. Use Tesseract OCR to extract text from images, and also extract data from excel sheets and store all the extracted data in a new workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50fc2705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts extracted and stored in C:/Users/Shreshtha/Downloads/Project UHC/Combined Trial Final.xlsx\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.utils import get_column_letter\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the directory containing the groups of images\n",
    "groups_directory = \"C:/Users/Shreshtha/Downloads/Project UHC/Output Folder 2\"\n",
    "\n",
    "# Path to the existing Excel workbook\n",
    "existing_excel_file_path = \"C:/Users/Shreshtha/Downloads/Project UHC/Trial 2.xlsx\"\n",
    "\n",
    "# Path to the new Excel workbook\n",
    "new_excel_file_path = \"C:/Users/Shreshtha/Downloads/Project UHC/Combined Trial Final.xlsx\"\n",
    "\n",
    "# Load the existing Excel data\n",
    "existing_workbook = load_workbook(existing_excel_file_path, read_only=True)\n",
    "existing_excel_data_dict = {}\n",
    "\n",
    "# Iterate through each sheet in the existing workbook\n",
    "for sheet_name in existing_workbook.sheetnames:\n",
    "    existing_excel_data_df = pd.read_excel(existing_excel_file_path, sheet_name=sheet_name, header=None)\n",
    "    existing_excel_data_dict[sheet_name] = existing_excel_data_df\n",
    "\n",
    "# Create a new Excel workbook\n",
    "new_workbook = Workbook()\n",
    "\n",
    "# Function to extract text from an image using OCR\n",
    "def extract_text_from_image(image_path):\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(Image.open(image_path))\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to process a group of images and extract text for each image\n",
    "def process_image_group(group_folder):\n",
    "    group_text_dict = {}\n",
    "\n",
    "    for filename in os.listdir(group_folder):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(group_folder, filename)\n",
    "\n",
    "            # Extract text from the image\n",
    "            text_data = extract_text_from_image(image_path)\n",
    "\n",
    "            # Store the extracted text for each image\n",
    "            group_text_dict[filename] = text_data\n",
    "\n",
    "    return group_text_dict\n",
    "\n",
    "# Iterate through each group folder in the groups directory\n",
    "for group_folder_name in os.listdir(groups_directory):\n",
    "    group_folder = os.path.join(groups_directory, group_folder_name)\n",
    "\n",
    "    if os.path.isdir(group_folder):\n",
    "        # Process each group of images\n",
    "        group_text_dict = process_image_group(group_folder)\n",
    "\n",
    "        if group_text_dict:\n",
    "            # Create a new sheet for each group's text data\n",
    "            group_sheet = new_workbook.create_sheet(title=f\"Group_{group_folder_name}\")\n",
    "\n",
    "            # Write the extracted text to the sheet\n",
    "            for filename, text_data in group_text_dict.items():\n",
    "                # Split the text into lines\n",
    "                lines = text_data.split('\\n')\n",
    "\n",
    "                # Write each line to a separate row in the sheet\n",
    "                for line in lines:\n",
    "                    group_sheet.append([filename, line])\n",
    "\n",
    "                # Add a blank row to create a gap between text of different images\n",
    "                group_sheet.append([])\n",
    "\n",
    "# Include existing Excel data in the new workbook\n",
    "for sheet_name, df in existing_excel_data_dict.items():\n",
    "    sheet = new_workbook.create_sheet(title=f\"Existing_{sheet_name}\")\n",
    "\n",
    "    # Write the existing Excel data to the sheet\n",
    "    for row in dataframe_to_rows(df, index=False, header=False):\n",
    "        sheet.append(row)\n",
    "\n",
    "# Save the new workbook\n",
    "new_workbook.save(new_excel_file_path)\n",
    "print(f\"Texts extracted and stored in {new_excel_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
