{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84d9b436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 converted to C:/Users/Shreshtha/Downloads//page_1.png\n",
      "Text block found at: (858, 956) Size: (18, 5)\n",
      "Text block found at: (767, 956) Size: (5, 5)\n",
      "Text block found at: (647, 956) Size: (8, 6)\n",
      "Text block found at: (877, 955) Size: (11, 7)\n",
      "Text block found at: (843, 955) Size: (13, 8)\n",
      "Text block found at: (810, 955) Size: (32, 8)\n",
      "Text block found at: (782, 955) Size: (26, 7)\n",
      "Text block found at: (773, 955) Size: (7, 6)\n",
      "Text block found at: (722, 955) Size: (43, 8)\n",
      "Text block found at: (658, 955) Size: (61, 8)\n",
      "Text block found at: (604, 955) Size: (41, 6)\n",
      "Text block found at: (583, 955) Size: (19, 6)\n",
      "Text block found at: (536, 955) Size: (45, 6)\n",
      "Text block found at: (512, 955) Size: (22, 7)\n",
      "Text block found at: (479, 955) Size: (30, 8)\n",
      "Text block found at: (435, 955) Size: (41, 6)\n",
      "Text block found at: (414, 955) Size: (19, 6)\n",
      "Text block found at: (391, 955) Size: (20, 6)\n",
      "Text block found at: (345, 955) Size: (44, 6)\n",
      "Text block found at: (320, 955) Size: (22, 7)\n",
      "Text block found at: (305, 955) Size: (14, 6)\n",
      "Text block found at: (278, 955) Size: (24, 8)\n",
      "Text block found at: (232, 955) Size: (44, 8)\n",
      "Text block found at: (199, 955) Size: (30, 8)\n",
      "Text block found at: (156, 955) Size: (41, 8)\n",
      "Text block found at: (141, 955) Size: (13, 6)\n",
      "Text block found at: (126, 955) Size: (13, 8)\n",
      "Text block found at: (81, 955) Size: (43, 6)\n",
      "Text block found at: (56, 955) Size: (23, 8)\n",
      "Text block found at: (23, 952) Size: (36, 22)\n",
      "Text block found at: (3, 482) Size: (15, 20)\n",
      "Text block found at: (19, 22) Size: (894, 952)\n",
      "Text block found at: (35, 7) Size: (6, 3)\n",
      "Text block found at: (73, 3) Size: (17, 9)\n",
      "Text block found at: (45, 3) Size: (24, 9)\n",
      "Text block found at: (11, 3) Size: (21, 9)\n",
      "Page 2 converted to C:/Users/Shreshtha/Downloads//page_2.png\n",
      "Text block found at: (25, 230) Size: (21, 7)\n",
      "Text block found at: (154, 229) Size: (48, 10)\n",
      "Text block found at: (50, 229) Size: (49, 8)\n",
      "Text block found at: (100, 217) Size: (5, 6)\n",
      "Text block found at: (108, 216) Size: (8, 7)\n",
      "Text block found at: (25, 216) Size: (21, 7)\n",
      "Text block found at: (154, 215) Size: (26, 10)\n",
      "Text block found at: (49, 215) Size: (50, 8)\n",
      "Text block found at: (25, 187) Size: (9, 7)\n",
      "Text block found at: (23, 186) Size: (187, 26)\n",
      "Text block found at: (38, 186) Size: (49, 8)\n",
      "Text block found at: (96, 172) Size: (8, 7)\n",
      "Text block found at: (25, 172) Size: (9, 7)\n",
      "Text block found at: (154, 171) Size: (26, 10)\n",
      "Text block found at: (37, 171) Size: (56, 8)\n",
      "Text block found at: (169, 158) Size: (11, 7)\n",
      "Text block found at: (25, 158) Size: (28, 9)\n",
      "Text block found at: (154, 157) Size: (15, 10)\n",
      "Text block found at: (105, 128) Size: (11, 4)\n",
      "Text block found at: (59, 128) Size: (1, 1)\n",
      "Text block found at: (196, 127) Size: (20, 6)\n",
      "Text block found at: (186, 127) Size: (8, 5)\n",
      "Text block found at: (22, 127) Size: (188, 27)\n",
      "Text block found at: (141, 127) Size: (11, 5)\n",
      "Text block found at: (118, 127) Size: (21, 5)\n",
      "Text block found at: (75, 127) Size: (28, 5)\n",
      "Text block found at: (62, 127) Size: (11, 5)\n",
      "Text block found at: (0, 127) Size: (60, 9)\n",
      "Text block found at: (154, 114) Size: (11, 7)\n",
      "Text block found at: (56, 114) Size: (23, 7)\n",
      "Text block found at: (25, 114) Size: (28, 9)\n",
      "Text block found at: (197, 100) Size: (11, 7)\n",
      "Text block found at: (25, 100) Size: (13, 7)\n",
      "Text block found at: (104, 99) Size: (38, 8)\n",
      "Text block found at: (52, 99) Size: (50, 10)\n",
      "Text block found at: (40, 99) Size: (10, 8)\n",
      "Text block found at: (204, 56) Size: (5, 7)\n",
      "Text block found at: (182, 56) Size: (21, 7)\n",
      "Text block found at: (177, 56) Size: (5, 7)\n",
      "Text block found at: (167, 56) Size: (9, 7)\n",
      "Text block found at: (155, 56) Size: (11, 7)\n",
      "Text block found at: (67, 56) Size: (21, 7)\n",
      "Text block found at: (25, 55) Size: (39, 8)\n",
      "Text block found at: (191, 41) Size: (17, 7)\n",
      "Text block found at: (25, 41) Size: (28, 9)\n",
      "Text block found at: (56, 40) Size: (37, 8)\n",
      "Text block found at: (153, 27) Size: (19, 7)\n",
      "Text block found at: (56, 27) Size: (27, 7)\n",
      "Text block found at: (25, 27) Size: (28, 9)\n",
      "Text block found at: (175, 26) Size: (13, 8)\n",
      "Text block found at: (35, 7) Size: (6, 3)\n",
      "Text block found at: (157, 3) Size: (17, 9)\n",
      "Text block found at: (91, 3) Size: (36, 8)\n",
      "Text block found at: (85, 3) Size: (6, 8)\n",
      "Text block found at: (45, 3) Size: (39, 9)\n",
      "Text block found at: (11, 3) Size: (21, 9)\n",
      "Text block found at: (131, 2) Size: (22, 10)\n",
      "Page 3 converted to C:/Users/Shreshtha/Downloads//page_3.png\n",
      "Text block found at: (300, 66) Size: (30, 9)\n",
      "Text block found at: (286, 66) Size: (11, 7)\n",
      "Text block found at: (49, 66) Size: (10, 7)\n",
      "Text block found at: (0, 66) Size: (47, 7)\n",
      "Text block found at: (180, 65) Size: (103, 58)\n",
      "Text block found at: (59, 65) Size: (118, 58)\n",
      "Text block found at: (35, 7) Size: (6, 3)\n",
      "Text block found at: (100, 3) Size: (15, 8)\n",
      "Text block found at: (79, 3) Size: (17, 9)\n",
      "Text block found at: (44, 3) Size: (31, 11)\n",
      "Text block found at: (11, 3) Size: (21, 9)\n",
      "Page 4 converted to C:/Users/Shreshtha/Downloads//page_4.png\n",
      "Text block found at: (162, 321) Size: (2, 1)\n",
      "Text block found at: (197, 319) Size: (13, 3)\n",
      "Text block found at: (194, 318) Size: (3, 4)\n",
      "Text block found at: (166, 318) Size: (18, 4)\n",
      "Text block found at: (82, 318) Size: (34, 4)\n",
      "Text block found at: (73, 267) Size: (19, 4)\n",
      "Text block found at: (53, 267) Size: (17, 4)\n",
      "Text block found at: (705, 192) Size: (10, 12)\n",
      "Text block found at: (2, 188) Size: (12, 16)\n",
      "Text block found at: (170, 116) Size: (37, 6)\n",
      "Text block found at: (123, 116) Size: (45, 6)\n",
      "Text block found at: (104, 116) Size: (17, 6)\n",
      "Text block found at: (71, 116) Size: (31, 5)\n",
      "Text block found at: (43, 116) Size: (26, 5)\n",
      "Text block found at: (23, 116) Size: (18, 5)\n",
      "Text block found at: (15, 63) Size: (688, 322)\n",
      "Text block found at: (152, 54) Size: (10, 4)\n",
      "Text block found at: (114, 54) Size: (7, 4)\n",
      "Text block found at: (221, 53) Size: (23, 5)\n",
      "Text block found at: (188, 53) Size: (31, 5)\n",
      "Text block found at: (164, 53) Size: (22, 5)\n",
      "Text block found at: (136, 53) Size: (14, 5)\n",
      "Text block found at: (123, 53) Size: (11, 5)\n",
      "Text block found at: (96, 53) Size: (16, 5)\n",
      "Text block found at: (49, 53) Size: (45, 5)\n",
      "Text block found at: (22, 53) Size: (222, 15)\n",
      "Text block found at: (72, 46) Size: (24, 5)\n",
      "Text block found at: (55, 46) Size: (15, 5)\n",
      "Text block found at: (23, 46) Size: (30, 5)\n",
      "Text block found at: (55, 38) Size: (17, 5)\n",
      "Text block found at: (23, 38) Size: (30, 6)\n",
      "Text block found at: (89, 31) Size: (18, 5)\n",
      "Text block found at: (77, 31) Size: (10, 6)\n",
      "Text block found at: (47, 31) Size: (28, 4)\n",
      "Text block found at: (23, 31) Size: (22, 5)\n",
      "Text block found at: (47, 23) Size: (22, 5)\n",
      "Text block found at: (23, 23) Size: (22, 6)\n",
      "Text block found at: (246, 22) Size: (453, 37)\n",
      "Text block found at: (35, 7) Size: (6, 3)\n",
      "Text block found at: (125, 3) Size: (6, 8)\n",
      "Text block found at: (72, 3) Size: (52, 9)\n",
      "Text block found at: (45, 3) Size: (24, 9)\n",
      "Text block found at: (11, 3) Size: (21, 9)\n",
      "Page 5 converted to C:/Users/Shreshtha/Downloads//page_5.png\n",
      "Text block found at: (344, 174) Size: (34, 11)\n",
      "Text block found at: (2, 174) Size: (6, 8)\n",
      "Text block found at: (327, 173) Size: (14, 9)\n",
      "Text block found at: (317, 173) Size: (7, 9)\n",
      "Text block found at: (154, 41) Size: (89, 7)\n",
      "Text block found at: (139, 41) Size: (13, 7)\n",
      "Text block found at: (98, 41) Size: (6, 7)\n",
      "Text block found at: (35, 41) Size: (39, 7)\n",
      "Text block found at: (25, 41) Size: (10, 7)\n",
      "Text block found at: (9, 40) Size: (307, 296)\n",
      "Text block found at: (77, 40) Size: (19, 8)\n",
      "Text block found at: (303, 28) Size: (43, 8)\n",
      "Text block found at: (188, 27) Size: (6, 7)\n",
      "Text block found at: (56, 27) Size: (20, 7)\n",
      "Text block found at: (234, 26) Size: (66, 8)\n",
      "Text block found at: (218, 26) Size: (13, 8)\n",
      "Text block found at: (197, 26) Size: (18, 10)\n",
      "Text block found at: (132, 26) Size: (52, 8)\n",
      "Text block found at: (113, 26) Size: (16, 8)\n",
      "Text block found at: (100, 26) Size: (10, 8)\n",
      "Text block found at: (79, 26) Size: (18, 8)\n",
      "Text block found at: (25, 26) Size: (28, 8)\n",
      "Text block found at: (35, 7) Size: (6, 3)\n",
      "Text block found at: (70, 3) Size: (18, 8)\n",
      "Text block found at: (44, 3) Size: (23, 9)\n",
      "Text block found at: (11, 3) Size: (21, 9)\n",
      "Page 6 converted to C:/Users/Shreshtha/Downloads//page_6.png\n",
      "Text block found at: (3, 284) Size: (17, 22)\n",
      "Text block found at: (22, 22) Size: (1014, 564)\n",
      "Text block found at: (35, 7) Size: (6, 3)\n",
      "Text block found at: (127, 3) Size: (26, 11)\n",
      "Text block found at: (85, 3) Size: (39, 9)\n",
      "Text block found at: (45, 3) Size: (36, 9)\n",
      "Text block found at: (11, 3) Size: (21, 9)\n",
      "Page 7 converted to C:/Users/Shreshtha/Downloads//page_7.png\n",
      "Text block found at: (110, 208) Size: (16, 9)\n",
      "Text block found at: (129, 207) Size: (23, 8)\n",
      "Text block found at: (109, 178) Size: (140, 10)\n",
      "Text block found at: (147, 165) Size: (12, 7)\n",
      "Text block found at: (110, 165) Size: (34, 7)\n",
      "Text block found at: (107, 151) Size: (2, 2)\n",
      "Text block found at: (191, 147) Size: (21, 6)\n",
      "Text block found at: (107, 147) Size: (2, 1)\n",
      "Text block found at: (359, 144) Size: (35, 12)\n",
      "Text block found at: (341, 144) Size: (14, 9)\n",
      "Text block found at: (293, 144) Size: (45, 12)\n",
      "Text block found at: (285, 144) Size: (7, 9)\n",
      "Text block found at: (258, 144) Size: (20, 9)\n",
      "Text block found at: (215, 144) Size: (39, 9)\n",
      "Text block found at: (59, 144) Size: (43, 12)\n",
      "Text block found at: (2, 144) Size: (53, 9)\n",
      "Text block found at: (109, 134) Size: (125, 19)\n",
      "Text block found at: (139, 123) Size: (21, 7)\n",
      "Text block found at: (110, 121) Size: (26, 7)\n",
      "Text block found at: (195, 92) Size: (25, 7)\n",
      "Text block found at: (173, 92) Size: (22, 7)\n",
      "Text block found at: (154, 92) Size: (16, 7)\n",
      "Text block found at: (266, 91) Size: (44, 8)\n",
      "Text block found at: (238, 91) Size: (26, 10)\n",
      "Text block found at: (223, 91) Size: (12, 8)\n",
      "Text block found at: (126, 91) Size: (25, 8)\n",
      "Text block found at: (110, 91) Size: (15, 8)\n",
      "Text block found at: (170, 76) Size: (32, 10)\n",
      "Text block found at: (154, 76) Size: (14, 8)\n",
      "Text block found at: (110, 76) Size: (42, 10)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import fitz\n",
    "\n",
    "def convert_pdf_to_images(pdf_path, output_folder):\n",
    "    # Open the PDF\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    \n",
    "    # Iterate through each page\n",
    "    for page_number in range(pdf_document.page_count):\n",
    "        # Get the page\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        \n",
    "        # Convert the page to a PIL image\n",
    "        image = page.get_pixmap()\n",
    "        \n",
    "        # Save the image\n",
    "        image_path = f\"{output_folder}/page_{page_number + 1}.png\"\n",
    "        image.save(image_path)\n",
    "        \n",
    "        print(f\"Page {page_number + 1} converted to {image_path}\")\n",
    "        \n",
    "        # Preprocess the image\n",
    "        preprocess_image(image_path)\n",
    "        \n",
    "def preprocess_image(image_path):\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply adaptive thresholding to binarize the image\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 4)\n",
    "    \n",
    "    # Apply morphological operations to remove noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    morphed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Perform layout analysis to identify text, tables, and forms\n",
    "    analyze_layout(morphed)\n",
    "    \n",
    "    # Save the preprocessed image\n",
    "    cv2.imwrite(image_path, morphed)\n",
    "    \n",
    "def analyze_layout(image):\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Check aspect ratio to identify potential text blocks\n",
    "        aspect_ratio = w / h\n",
    "        if aspect_ratio > 0.5 and aspect_ratio < 20:\n",
    "            print(\"Text block found at:\", (x, y), \"Size:\", (w, h))\n",
    "        else:\n",
    "            # Check if the contour area is larger than a certain threshold\n",
    "            contour_area = cv2.contourArea(contour)\n",
    "            if contour_area > 1000:\n",
    "                # Check if the contour is roughly rectangular\n",
    "                perimeter = cv2.arcLength(contour, True)\n",
    "                approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
    "                if len(approx) == 4:\n",
    "                    # This contour may represent a table or form\n",
    "                    print(\"Potential table or form found at:\", (x, y), \"Size:\", (w, h))\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"C:/Users/Shreshtha/Labelled_MNS_Sample.pdf\"\n",
    "output_folder = \"C:/Users/Shreshtha/Downloads/\"\n",
    "convert_pdf_to_images(pdf_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b328b4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 converted to C:/Users/Shreshtha/Downloads//page_1.png\n",
      "Page 2 converted to C:/Users/Shreshtha/Downloads//page_2.png\n",
      "Page 3 converted to C:/Users/Shreshtha/Downloads//page_3.png\n",
      "Page 4 converted to C:/Users/Shreshtha/Downloads//page_4.png\n",
      "Page 5 converted to C:/Users/Shreshtha/Downloads//page_5.png\n",
      "Page 6 converted to C:/Users/Shreshtha/Downloads//page_6.png\n",
      "Page 7 converted to C:/Users/Shreshtha/Downloads//page_7.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import fitz\n",
    "\n",
    "def convert_pdf_to_images(pdf_path, output_folder):\n",
    "    # Open the PDF\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    \n",
    "    # Iterate through each page\n",
    "    for page_number in range(pdf_document.page_count):\n",
    "        # Get the page\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        \n",
    "        # Convert the page to a PIL image\n",
    "        image = page.get_pixmap()\n",
    "        \n",
    "        # Save the image\n",
    "        image_path = f\"{output_folder}/page_{page_number + 1}.png\"\n",
    "        image.save(image_path)\n",
    "        \n",
    "        print(f\"Page {page_number + 1} converted to {image_path}\")\n",
    "        \n",
    "        # Preprocess the image\n",
    "        preprocess_image(image_path)\n",
    "        \n",
    "def preprocess_image(image_path):\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Save the preprocessed image\n",
    "    cv2.imwrite(image_path, gray)\n",
    "    \n",
    "# Example usage\n",
    "pdf_path =\"C:/Users/Shreshtha/Labelled_MNS_Sample.pdf\"\n",
    "output_folder = \"C:/Users/Shreshtha/Downloads/\"\n",
    "convert_pdf_to_images(pdf_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2402318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 converted to C:/Users/Shreshtha/Downloads//page_1.png\n",
      "Page 2 converted to C:/Users/Shreshtha/Downloads//page_2.png\n",
      "Page 3 converted to C:/Users/Shreshtha/Downloads//page_3.png\n",
      "Page 4 converted to C:/Users/Shreshtha/Downloads//page_4.png\n",
      "Page 5 converted to C:/Users/Shreshtha/Downloads//page_5.png\n",
      "Page 6 converted to C:/Users/Shreshtha/Downloads//page_6.png\n",
      "Page 7 converted to C:/Users/Shreshtha/Downloads//page_7.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import fitz\n",
    "\n",
    "def convert_pdf_to_images(pdf_path, output_folder):\n",
    "    # Open the PDF\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    \n",
    "    # Iterate through each page\n",
    "    for page_number in range(pdf_document.page_count):\n",
    "        # Get the page\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        \n",
    "        # Convert the page to a PIL image\n",
    "        image = page.get_pixmap()\n",
    "        \n",
    "        # Save the image\n",
    "        image_path = f\"{output_folder}/page_{page_number + 1}.png\"\n",
    "        image.save(image_path)\n",
    "        \n",
    "        print(f\"Page {page_number + 1} converted to {image_path}\")\n",
    "        \n",
    "        # Preprocess the image\n",
    "        preprocess_image(image_path)\n",
    "        \n",
    "def preprocess_image(image_path):\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_gray = clahe.apply(gray)\n",
    "    \n",
    "    # Apply edge enhancement\n",
    "    edges = cv2.Canny(enhanced_gray, 50, 150)\n",
    "    \n",
    "    # Combine original grayscale image with edges\n",
    "    enhanced_image = cv2.addWeighted(gray, 0.5, edges, 0.5, 0)\n",
    "    \n",
    "    # Save the preprocessed image\n",
    "    cv2.imwrite(image_path, enhanced_image)\n",
    "    \n",
    "# Example usage\n",
    "pdf_path =\"C:/Users/Shreshtha/Labelled_MNS_Sample.pdf\"\n",
    "output_folder = \"C:/Users/Shreshtha/Downloads/\"\n",
    "convert_pdf_to_images(pdf_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3ebf491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 converted to C:/Users/Shreshtha/Downloads//page_1.png\n",
      "Page 2 converted to C:/Users/Shreshtha/Downloads//page_2.png\n",
      "Page 3 converted to C:/Users/Shreshtha/Downloads//page_3.png\n",
      "Page 4 converted to C:/Users/Shreshtha/Downloads//page_4.png\n",
      "Page 5 converted to C:/Users/Shreshtha/Downloads//page_5.png\n",
      "Page 6 converted to C:/Users/Shreshtha/Downloads//page_6.png\n",
      "Page 7 converted to C:/Users/Shreshtha/Downloads//page_7.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import fitz\n",
    "\n",
    "def convert_pdf_to_images(pdf_path, output_folder):\n",
    "    # Open the PDF\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    \n",
    "    # Iterate through each page\n",
    "    for page_number in range(pdf_document.page_count):\n",
    "        # Get the page\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        \n",
    "        # Convert the page to a PIL image\n",
    "        image = page.get_pixmap()\n",
    "        \n",
    "        # Save the image\n",
    "        image_path = f\"{output_folder}/page_{page_number + 1}.png\"\n",
    "        image.save(image_path)\n",
    "        \n",
    "        print(f\"Page {page_number + 1} converted to {image_path}\")\n",
    "        \n",
    "        # Preprocess the image\n",
    "        preprocess_image(image_path)\n",
    "        \n",
    "def preprocess_image(image_path):\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Apply contrast enhancement\n",
    "    enhanced_image = enhance_contrast(image)\n",
    "    \n",
    "    # Apply edge enhancement\n",
    "    enhanced_image = enhance_edges(enhanced_image)\n",
    "    \n",
    "    # Save the preprocessed image\n",
    "    cv2.imwrite(image_path, enhanced_image)\n",
    "    \n",
    "def enhance_contrast(image):\n",
    "    # Convert the image to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    # Split the LAB image into channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Apply CLAHE to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_l = clahe.apply(l)\n",
    "    \n",
    "    # Merge the enhanced L channel with the original A and B channels\n",
    "    enhanced_lab = cv2.merge((enhanced_l, a, b))\n",
    "    \n",
    "    # Convert the LAB image back to BGR color space\n",
    "    enhanced_image = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return enhanced_image\n",
    "    \n",
    "def enhance_edges(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply edge enhancement using the Canny edge detector\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    \n",
    "    # Create a mask to retain only the edges\n",
    "    mask = np.zeros_like(image)\n",
    "    mask[edges != 0] = image[edges != 0]\n",
    "    \n",
    "    # Combine the original image with the edges\n",
    "    enhanced_image = cv2.addWeighted(image, 0.5, mask, 0.5, 0)\n",
    "    \n",
    "    return enhanced_image\n",
    "    \n",
    "# Example usage\n",
    "pdf_path =\"C:/Users/Shreshtha/Labelled_MNS_Sample.pdf\"\n",
    "output_folder = \"C:/Users/Shreshtha/Downloads/\"\n",
    "convert_pdf_to_images(pdf_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b01c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 converted to C:/Users/Shreshtha/Downloads//page_1.png\n",
      "Page 2 converted to C:/Users/Shreshtha/Downloads//page_2.png\n",
      "Page 3 converted to C:/Users/Shreshtha/Downloads//page_3.png\n",
      "Page 4 converted to C:/Users/Shreshtha/Downloads//page_4.png\n",
      "Page 5 converted to C:/Users/Shreshtha/Downloads//page_5.png\n",
      "Page 6 converted to C:/Users/Shreshtha/Downloads//page_6.png\n",
      "Page 7 converted to C:/Users/Shreshtha/Downloads//page_7.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import fitz\n",
    "\n",
    "def convert_pdf_to_images(pdf_path, output_folder):\n",
    "    # Open the PDF\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    \n",
    "    # Iterate through each page\n",
    "    for page_number in range(pdf_document.page_count):\n",
    "        # Get the page\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        \n",
    "        # Convert the page to a PIL image\n",
    "        image = page.get_pixmap()\n",
    "        \n",
    "        # Save the image\n",
    "        image_path = f\"{output_folder}/page_{page_number + 1}.png\"\n",
    "        image.save(image_path)\n",
    "        \n",
    "        print(f\"Page {page_number + 1} converted to {image_path}\")\n",
    "        \n",
    "        # Preprocess the image\n",
    "        preprocess_image(image_path)\n",
    "        \n",
    "def preprocess_image(image_path):\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Apply contrast enhancement\n",
    "    enhanced_image = enhance_contrast(image)\n",
    "    \n",
    "    # Apply edge enhancement\n",
    "    enhanced_image = enhance_edges(enhanced_image)\n",
    "    \n",
    "    # Save the preprocessed image\n",
    "    cv2.imwrite(image_path, enhanced_image)\n",
    "    \n",
    "def enhance_contrast(image):\n",
    "    # Convert the image to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    # Split the LAB image into channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Apply CLAHE to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))  # Adjust clipLimit for more contrast\n",
    "    enhanced_l = clahe.apply(l)\n",
    "    \n",
    "    # Merge the enhanced L channel with the original A and B channels\n",
    "    enhanced_lab = cv2.merge((enhanced_l, a, b))\n",
    "    \n",
    "    # Convert the LAB image back to BGR color space\n",
    "    enhanced_image = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return enhanced_image\n",
    "    \n",
    "def enhance_edges(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply edge enhancement using the Canny edge detector\n",
    "    edges = cv2.Canny(gray, 100, 200)  # Adjust threshold values for more/less edges\n",
    "    \n",
    "    # Create a mask to retain only the edges\n",
    "    mask = np.zeros_like(image)\n",
    "    mask[edges != 0] = image[edges != 0]\n",
    "    \n",
    "    # Combine the original image with the edges\n",
    "    enhanced_image = cv2.addWeighted(image, 0.7, mask, 0.3, 0)  # Adjust weights for better visibility\n",
    "    \n",
    "    return enhanced_image\n",
    "    \n",
    "# Example usage\n",
    "pdf_path =\"C:/Users/Shreshtha/Labelled_MNS_Sample.pdf\"\n",
    "output_folder = \"C:/Users/Shreshtha/Downloads/\"\n",
    "convert_pdf_to_images(pdf_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d8a70fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 converted to C:/Users/Shreshtha/Downloads//page_1.png\n",
      "Page 2 converted to C:/Users/Shreshtha/Downloads//page_2.png\n",
      "Page 3 converted to C:/Users/Shreshtha/Downloads//page_3.png\n",
      "Page 4 converted to C:/Users/Shreshtha/Downloads//page_4.png\n",
      "Page 5 converted to C:/Users/Shreshtha/Downloads//page_5.png\n",
      "Page 6 converted to C:/Users/Shreshtha/Downloads//page_6.png\n",
      "Page 7 converted to C:/Users/Shreshtha/Downloads//page_7.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import fitz\n",
    "\n",
    "def convert_pdf_to_images(pdf_path, output_folder):\n",
    "    # Open the PDF\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    \n",
    "    # Iterate through each page\n",
    "    for page_number in range(pdf_document.page_count):\n",
    "        # Get the page\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        \n",
    "        # Convert the page to a PIL image\n",
    "        image = page.get_pixmap()\n",
    "        \n",
    "        # Save the image\n",
    "        image_path = f\"{output_folder}/page_{page_number + 1}.png\"\n",
    "        image.save(image_path)\n",
    "        \n",
    "        print(f\"Page {page_number + 1} converted to {image_path}\")\n",
    "        \n",
    "        # Preprocess the image\n",
    "        preprocess_image(image_path)\n",
    "        \n",
    "def preprocess_image(image_path):\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Apply contrast enhancement\n",
    "    enhanced_image = enhance_contrast(image)\n",
    "    \n",
    "    # Apply edge enhancement\n",
    "    enhanced_image = enhance_edges(enhanced_image)\n",
    "    \n",
    "    # Save the preprocessed image\n",
    "    cv2.imwrite(image_path, enhanced_image)\n",
    "    \n",
    "def enhance_contrast(image):\n",
    "    # Convert the image to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    # Split the LAB image into channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Apply CLAHE to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_l = clahe.apply(l)\n",
    "    \n",
    "    # Merge the enhanced L channel with the original A and B channels\n",
    "    enhanced_lab = cv2.merge((enhanced_l, a, b))\n",
    "    \n",
    "    # Convert the LAB image back to BGR color space\n",
    "    enhanced_image = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    # Ensure that white areas remain white\n",
    "    mask = cv2.threshold(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), 240, 255, cv2.THRESH_BINARY)[1]\n",
    "    enhanced_image[np.where(mask == 255)] = image[np.where(mask == 255)]\n",
    "    \n",
    "    return enhanced_image\n",
    "    \n",
    "def enhance_edges(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply edge enhancement using the Canny edge detector\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    \n",
    "    # Create a mask to retain only the edges\n",
    "    mask = np.zeros_like(image)\n",
    "    mask[edges != 0] = image[edges != 0]\n",
    "    \n",
    "    # Combine the original image with the edges\n",
    "    enhanced_image = cv2.addWeighted(image, 0.7, mask, 0.3, 0)\n",
    "    \n",
    "    return enhanced_image\n",
    "    \n",
    "# Example usage\n",
    "pdf_path =\"C:/Users/Shreshtha/Labelled_MNS_Sample.pdf\"\n",
    "output_folder = \"C:/Users/Shreshtha/Downloads/\"\n",
    "convert_pdf_to_images(pdf_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583b6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 converted to C:/Users/Shreshtha/Downloads//page_1.png\n",
      "Text detected at: (21, 21) Size: (891, 926)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import fitz\n",
    "\n",
    "def convert_pdf_to_images(pdf_path, output_folder):\n",
    "    # Open the PDF\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    \n",
    "    # Iterate through each page\n",
    "    for page_number in range(pdf_document.page_count):\n",
    "        # Get the page\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        \n",
    "        # Convert the page to a PIL image\n",
    "        image = page.get_pixmap()\n",
    "        \n",
    "        # Save the image\n",
    "        image_path = f\"{output_folder}/page_{page_number + 1}.png\"\n",
    "        image.save(image_path)\n",
    "        \n",
    "        print(f\"Page {page_number + 1} converted to {image_path}\")\n",
    "        \n",
    "        # Preprocess the image\n",
    "        preprocess_image(image_path)\n",
    "        \n",
    "        # Perform layout analysis\n",
    "        analyze_layout(image_path)\n",
    "        \n",
    "def preprocess_image(image_path):\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Apply contrast enhancement\n",
    "    enhanced_image = enhance_contrast(image)\n",
    "    \n",
    "    # Apply edge enhancement\n",
    "    enhanced_image = enhance_edges(enhanced_image)\n",
    "    \n",
    "    # Save the preprocessed image\n",
    "    cv2.imwrite(image_path, enhanced_image)\n",
    "    \n",
    "def enhance_contrast(image):\n",
    "    # Convert the image to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    # Split the LAB image into channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Apply CLAHE to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_l = clahe.apply(l)\n",
    "    \n",
    "    # Merge the enhanced L channel with the original A and B channels\n",
    "    enhanced_lab = cv2.merge((enhanced_l, a, b))\n",
    "    \n",
    "    # Convert the LAB image back to BGR color space\n",
    "    enhanced_image = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    # Ensure that white areas remain white\n",
    "    mask = cv2.threshold(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), 240, 255, cv2.THRESH_BINARY)[1]\n",
    "    enhanced_image[np.where(mask == 255)] = image[np.where(mask == 255)]\n",
    "    \n",
    "    return enhanced_image\n",
    "    \n",
    "def enhance_edges(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply edge enhancement using the Canny edge detector\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    \n",
    "    # Create a mask to retain only the edges\n",
    "    mask = np.zeros_like(image)\n",
    "    mask[edges != 0] = image[edges != 0]\n",
    "    \n",
    "    # Combine the original image with the edges\n",
    "    enhanced_image = cv2.addWeighted(image, 0.7, mask, 0.3, 0)\n",
    "    \n",
    "    return enhanced_image\n",
    "    \n",
    "def analyze_layout(image_path):\n",
    "    # Read the preprocessed image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding to binarize the image\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Iterate through contours\n",
    "    for contour in contours:\n",
    "        # Calculate contour area\n",
    "        area = cv2.contourArea(contour)\n",
    "        \n",
    "        # If contour area is small, skip\n",
    "        if area < 100:\n",
    "            continue\n",
    "        \n",
    "        # Calculate contour perimeter\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        \n",
    "        # Approximate polygonal curves\n",
    "        approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
    "        \n",
    "        # Get bounding rectangle\n",
    "        x, y, w, h = cv2.boundingRect(approx)\n",
    "        \n",
    "        # Draw bounding rectangle (for visualization)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Classify contour based on aspect ratio\n",
    "        aspect_ratio = w / h\n",
    "        \n",
    "        if 0.5 < aspect_ratio < 20:\n",
    "            print(\"Text detected at:\", (x, y), \"Size:\", (w, h))\n",
    "            # You can further process the text region here\n",
    "        elif 0.1 < aspect_ratio < 5:\n",
    "            print(\"Potential table or form detected at:\", (x, y), \"Size:\", (w, h))\n",
    "            # You can further process the table or form region here\n",
    "    \n",
    "    # Display the image with contours\n",
    "    cv2.imshow(\"Layout Analysis\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "# Example usage\n",
    "pdf_path =\"C:/Users/Shreshtha/Labelled_MNS_Sample.pdf\"\n",
    "output_folder = \"C:/Users/Shreshtha/Downloads/\"\n",
    "convert_pdf_to_images(pdf_path, output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
