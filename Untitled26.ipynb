{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a92e955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-documentai in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (2.21.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (2.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-cloud-documentai) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-cloud-documentai) (4.23.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (1.62.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (2.27.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (1.60.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (2023.11.17)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-documentai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b7a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ebffbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"C:/Users/Shreshtha/Downloads/balmy-outcome-412805-7a02be612f44.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92ced378",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'balmy-outcome-412805' \n",
    "location = 'us' \n",
    "processor_id = '1c327dd87f42b98b' \n",
    "processor_version = 'rc' \n",
    "file_path = \"gs://blogtrial/Trial 2-2.png\" \n",
    "mime_type = 'image/png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47c64294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_process(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    ") -> documentai.Document:\n",
    "    \"\"\"\n",
    "    A function to process a document online using Google Document AI.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define an options dictionary, which includes the API's URL. This is used to connect to Google's Document AI service\n",
    "    opts = {\"api_endpoint\": f\"{location}-documentai.googleapis.com\"}\n",
    "\n",
    "    # Create a Document AI client, think of it as our bridge for communicating with Google's services\n",
    "    documentai_client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "\n",
    "    # Generate the complete name of the processor\n",
    "    # You need to first create a processor in the Google Cloud console\n",
    "    resource_name = documentai_client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    # Read in the document you want to analyze (like an image or PDF), and store it in the variable image_content\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "        # Convert the read document into a format that Google Document AI can understand, i.e., a RawDocument object\n",
    "        raw_document = documentai.RawDocument(\n",
    "            content=image_content, mime_type=mime_type\n",
    "        )\n",
    "        # Create a request, which includes the name of the processor and the document we want to analyze\n",
    "        request = documentai.ProcessRequest(\n",
    "            name=resource_name, raw_document=raw_document\n",
    "        )\n",
    "        # Send our request and receive the analysis results\n",
    "        result = documentai_client.process_document(request=request)\n",
    "\n",
    "        # Return this analysis result\n",
    "        return result.document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab30f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_text(text: str): \n",
    "    \"\"\" Removes spaces and newline characters. \"\"\" \n",
    "    return text.strip().replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19cb35ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'gs://blogtrial/Trial 2-2.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m document \u001b[38;5;241m=\u001b[39m online_process(\n\u001b[0;32m      2\u001b[0m     project_id\u001b[38;5;241m=\u001b[39mproject_id,\n\u001b[0;32m      3\u001b[0m     location\u001b[38;5;241m=\u001b[39mlocation,\n\u001b[0;32m      4\u001b[0m     processor_id\u001b[38;5;241m=\u001b[39mprocessor_id,\n\u001b[0;32m      5\u001b[0m     file_path\u001b[38;5;241m=\u001b[39mfile_path,\n\u001b[0;32m      6\u001b[0m     mime_type\u001b[38;5;241m=\u001b[39mmime_type,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m names \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m name_confidence \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m, in \u001b[0;36monline_process\u001b[1;34m(project_id, location, processor_id, file_path, mime_type)\u001b[0m\n\u001b[0;32m     20\u001b[0m resource_name \u001b[38;5;241m=\u001b[39m documentai_client\u001b[38;5;241m.\u001b[39mprocessor_path(project_id, location, processor_id)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Read in the document you want to analyze (like an image or PDF), and store it in the variable image_content\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[0;32m     24\u001b[0m     image_content \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Convert the read document into a format that Google Document AI can understand, i.e., a RawDocument object\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'gs://blogtrial/Trial 2-2.png'"
     ]
    }
   ],
   "source": [
    "document = online_process(\n",
    "    project_id=project_id,\n",
    "    location=location,\n",
    "    processor_id=processor_id,\n",
    "    file_path=file_path,\n",
    "    mime_type=mime_type,\n",
    ")\n",
    "\n",
    "names = []\n",
    "name_confidence = []\n",
    "values = []\n",
    "value_confidence = []\n",
    "\n",
    "for page in document.pages:\n",
    "    for field in page.form_fields:\n",
    "        names.append(trim_text(field.field_name.text_anchor.content))\n",
    "        name_confidence.append(field.field_name.confidence)\n",
    "        values.append(trim_text(field.field_value.text_anchor.content))\n",
    "        value_confidence.append(field.field_value.confidence)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Field Name\": names,\n",
    "        \"Field Name Confidence\": name_confidence,\n",
    "        \"Field Value\": values,\n",
    "        \"Field Value Confidence\": value_confidence,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "479e22c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-documentai in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (2.21.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (2.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-cloud-documentai) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-cloud-documentai) (4.23.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (1.62.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (2.27.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (1.60.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (2023.11.17)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (0.4.8)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: '\"C:/Users/ShreshthaDownloads/ProjectUHC/extracted_images/Trial 2-2.png\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Download the file from Google Cloud Storage\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m download_file_from_gcs(gcs_bucket, gcs_blob_name, local_file_path)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Use the local file path in your function\u001b[39;00m\n\u001b[0;32m     74\u001b[0m document \u001b[38;5;241m=\u001b[39m online_process(\n\u001b[0;32m     75\u001b[0m     project_id\u001b[38;5;241m=\u001b[39mproject_id,\n\u001b[0;32m     76\u001b[0m     location\u001b[38;5;241m=\u001b[39mlocation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m     mime_type\u001b[38;5;241m=\u001b[39mmime_type,\n\u001b[0;32m     80\u001b[0m )\n",
      "Cell \u001b[1;32mIn[28], line 25\u001b[0m, in \u001b[0;36mdownload_file_from_gcs\u001b[1;34m(bucket_name, blob_name, local_path)\u001b[0m\n\u001b[0;32m     23\u001b[0m bucket \u001b[38;5;241m=\u001b[39m storage_client\u001b[38;5;241m.\u001b[39mbucket(bucket_name)\n\u001b[0;32m     24\u001b[0m blob \u001b[38;5;241m=\u001b[39m bucket\u001b[38;5;241m.\u001b[39mblob(blob_name)\n\u001b[1;32m---> 25\u001b[0m blob\u001b[38;5;241m.\u001b[39mdownload_to_filename(local_path)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\cloud\\storage\\blob.py:1282\u001b[0m, in \u001b[0;36mBlob.download_to_filename\u001b[1;34m(self, filename, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_to_filename\u001b[39m(\n\u001b[0;32m   1175\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1176\u001b[0m     filename,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     retry\u001b[38;5;241m=\u001b[39mDEFAULT_RETRY,\n\u001b[0;32m   1190\u001b[0m ):\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download the contents of this blob into a named file.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \n\u001b[0;32m   1193\u001b[0m \u001b[38;5;124;03m    If :attr:`user_project` is set on the bucket, bills the API request\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;124;03m    :raises: :class:`google.cloud.exceptions.NotFound`\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_filename_and_download(\n\u001b[0;32m   1283\u001b[0m         filename,\n\u001b[0;32m   1284\u001b[0m         client\u001b[38;5;241m=\u001b[39mclient,\n\u001b[0;32m   1285\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m   1286\u001b[0m         end\u001b[38;5;241m=\u001b[39mend,\n\u001b[0;32m   1287\u001b[0m         raw_download\u001b[38;5;241m=\u001b[39mraw_download,\n\u001b[0;32m   1288\u001b[0m         if_etag_match\u001b[38;5;241m=\u001b[39mif_etag_match,\n\u001b[0;32m   1289\u001b[0m         if_etag_not_match\u001b[38;5;241m=\u001b[39mif_etag_not_match,\n\u001b[0;32m   1290\u001b[0m         if_generation_match\u001b[38;5;241m=\u001b[39mif_generation_match,\n\u001b[0;32m   1291\u001b[0m         if_generation_not_match\u001b[38;5;241m=\u001b[39mif_generation_not_match,\n\u001b[0;32m   1292\u001b[0m         if_metageneration_match\u001b[38;5;241m=\u001b[39mif_metageneration_match,\n\u001b[0;32m   1293\u001b[0m         if_metageneration_not_match\u001b[38;5;241m=\u001b[39mif_metageneration_not_match,\n\u001b[0;32m   1294\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   1295\u001b[0m         checksum\u001b[38;5;241m=\u001b[39mchecksum,\n\u001b[0;32m   1296\u001b[0m         retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[0;32m   1297\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\cloud\\storage\\blob.py:1157\u001b[0m, in \u001b[0;36mBlob._handle_filename_and_download\u001b[1;34m(self, filename, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Download the contents of this blob into a named file.\u001b[39;00m\n\u001b[0;32m   1149\u001b[0m \n\u001b[0;32m   1150\u001b[0m \u001b[38;5;124;03m:type filename: str\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[38;5;124;03mFor *args and **kwargs, refer to the documentation for download_to_filename() for more information.\u001b[39;00m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1157\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file_obj:\n\u001b[0;32m   1158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prep_and_do_download(\n\u001b[0;32m   1159\u001b[0m             file_obj,\n\u001b[0;32m   1160\u001b[0m             \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   1161\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1162\u001b[0m         )\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m resumable_media\u001b[38;5;241m.\u001b[39mDataCorruption:\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;66;03m# Delete the corrupt downloaded file.\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: '\"C:/Users/ShreshthaDownloads/ProjectUHC/extracted_images/Trial 2-2.png\"'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os \n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai \n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"C:/Users/Shreshtha/Downloads/balmy-outcome-412805-7a02be612f44.json\"\n",
    "\n",
    "project_id = 'balmy-outcome-412805' \n",
    "location = 'us' \n",
    "processor_id = '1c327dd87f42b98b' \n",
    "processor_version = 'rc' \n",
    "gcs_bucket = 'blogtrial'\n",
    "gcs_blob_name = 'Trial 2-2.png'\n",
    "local_file_path = '\"C:/Users/ShreshthaDownloads/ProjectUHC/extracted_images/Trial 2-2.png\"'  # Change this to your desired local path\n",
    "mime_type = 'image/png'\n",
    "\n",
    "def download_file_from_gcs(bucket_name, blob_name, local_path):\n",
    "    \"\"\"Download a file from Google Cloud Storage to a local path.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.download_to_filename(local_path)\n",
    "\n",
    "def online_process(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    ") -> documentai.Document:\n",
    "    \"\"\"\n",
    "    A function to process a document online using Google Document AI.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define an options dictionary, which includes the API's URL. This is used to connect to Google's Document AI service\n",
    "    opts = {\"api_endpoint\": f\"{location}-documentai.googleapis.com\"}\n",
    "\n",
    "    # Create a Document AI client, think of it as our bridge for communicating with Google's services\n",
    "    documentai_client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "\n",
    "    # Generate the complete name of the processor\n",
    "    # You need to first create a processor in the Google Cloud console\n",
    "    resource_name = documentai_client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    # Read in the document you want to analyze (like an image or PDF), and store it in the variable image_content\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "        # Convert the read document into a format that Google Document AI can understand, i.e., a RawDocument object\n",
    "        raw_document = documentai.RawDocument(\n",
    "            content=image_content, mime_type=mime_type\n",
    "        )\n",
    "        # Create a request, which includes the name of the processor and the document we want to analyze\n",
    "        request = documentai.ProcessRequest(\n",
    "            name=resource_name, raw_document=raw_document\n",
    "        )\n",
    "        # Send our request and receive the analysis results\n",
    "        result = documentai_client.process_document(request=request)\n",
    "\n",
    "        # Return this analysis result\n",
    "        return result.document\n",
    "\n",
    "def trim_text(text: str): \n",
    "    \"\"\" Removes spaces and newline characters. \"\"\" \n",
    "    return text.strip().replace(\"\\n\", \" \")\n",
    "\n",
    "# Download the file from Google Cloud Storage\n",
    "download_file_from_gcs(gcs_bucket, gcs_blob_name, local_file_path)\n",
    "\n",
    "# Use the local file path in your function\n",
    "document = online_process(\n",
    "    project_id=project_id,\n",
    "    location=location,\n",
    "    processor_id=processor_id,\n",
    "    file_path=local_file_path,  # Use the local path here\n",
    "    mime_type=mime_type,\n",
    ")\n",
    "\n",
    "names = []\n",
    "name_confidence = []\n",
    "values = []\n",
    "value_confidence = []\n",
    "\n",
    "for page in document.pages:\n",
    "    for field in page.form_fields:\n",
    "        names.append(trim_text(field.field_name.text_anchor.content))\n",
    "        name_confidence.append(field.field_name.confidence)\n",
    "        values.append(trim_text(field.field_value.text_anchor.content))\n",
    "        value_confidence.append(field.field_value.confidence)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Field Name\": names,\n",
    "        \"Field Name Confidence\": name_confidence,\n",
    "        \"Field Value\": values,\n",
    "        \"Field Value Confidence\": value_confidence,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd17324",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddd96719",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os \n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai \n",
    "import pandas as pd\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"C:/Users/Shreshtha/Downloads/balmy-outcome-412805-7a02be612f44.json\"\n",
    "\n",
    "project_id = 'balmy-outcome-412805' \n",
    "location = 'us' \n",
    "processor_id = '1c327dd87f42b98b' \n",
    "processor_version = 'rc' \n",
    "local_file_path = \"C:/Users/Shreshtha/Downloads/ProjectUHC/extracted_images\\Trial 2-2.png\"  # Change this to your downloaded local path\n",
    "mime_type = 'image/png'\n",
    "\n",
    "def online_process(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    ") -> documentai.Document:\n",
    "    \"\"\"\n",
    "    A function to process a document online using Google Document AI.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define an options dictionary, which includes the API's URL. This is used to connect to Google's Document AI service\n",
    "    opts = {\"api_endpoint\": f\"{location}-documentai.googleapis.com\"}\n",
    "\n",
    "    # Create a Document AI client, think of it as our bridge for communicating with Google's services\n",
    "    documentai_client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "\n",
    "    # Generate the complete name of the processor\n",
    "    # You need to first create a processor in the Google Cloud console\n",
    "    resource_name = documentai_client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    # Read in the document you want to analyze (like an image or PDF), and store it in the variable image_content\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "        # Convert the read document into a format that Google Document AI can understand, i.e., a RawDocument object\n",
    "        raw_document = documentai.RawDocument(\n",
    "            content=image_content, mime_type=mime_type\n",
    "        )\n",
    "        # Create a request, which includes the name of the processor and the document we want to analyze\n",
    "        request = documentai.ProcessRequest(\n",
    "            name=resource_name, raw_document=raw_document\n",
    "        )\n",
    "        # Send our request and receive the analysis results\n",
    "        result = documentai_client.process_document(request=request)\n",
    "\n",
    "        # Return this analysis result\n",
    "        return result.document\n",
    "\n",
    "def trim_text(text: str): \n",
    "    \"\"\" Removes spaces and newline characters. \"\"\" \n",
    "    return text.strip().replace(\"\\n\", \" \")\n",
    "\n",
    "# Use the local file path in your function\n",
    "document = online_process(\n",
    "    project_id=project_id,\n",
    "    location=location,\n",
    "    processor_id=processor_id,\n",
    "    file_path=local_file_path,  # Use the local path here\n",
    "    mime_type=mime_type,\n",
    ")\n",
    "\n",
    "names = []\n",
    "name_confidence = []\n",
    "values = []\n",
    "value_confidence = []\n",
    "\n",
    "for page in document.pages:\n",
    "    for field in page.form_fields:\n",
    "        names.append(trim_text(field.field_name.text_anchor.content))\n",
    "        name_confidence.append(field.field_name.confidence)\n",
    "        values.append(trim_text(field.field_value.text_anchor.content))\n",
    "        value_confidence.append(field.field_value.confidence)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Field Name\": names,\n",
    "        \"Field Name Confidence\": name_confidence,\n",
    "        \"Field Value\": values,\n",
    "        \"Field Value Confidence\": value_confidence,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe5eaab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "040f0bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field Name</th>\n",
       "      <th>Field Name Confidence</th>\n",
       "      <th>Field Value</th>\n",
       "      <th>Field Value Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Specialist:</td>\n",
       "      <td>0.969713</td>\n",
       "      <td>No Charge after Deductible</td>\n",
       "      <td>0.969713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Family M.O.O.P.</td>\n",
       "      <td>0.959258</td>\n",
       "      <td>$8,000</td>\n",
       "      <td>0.959258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCP:</td>\n",
       "      <td>0.946640</td>\n",
       "      <td>No Charge after Deductible</td>\n",
       "      <td>0.946640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Family M.O.O.P.</td>\n",
       "      <td>0.932364</td>\n",
       "      <td>$11.700</td>\n",
       "      <td>0.932364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coinsurance:</td>\n",
       "      <td>0.913815</td>\n",
       "      <td>None</td>\n",
       "      <td>0.913815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Inpatient:</td>\n",
       "      <td>0.912482</td>\n",
       "      <td>No Charge after Deductible</td>\n",
       "      <td>0.912482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Outpatient Freestanding:</td>\n",
       "      <td>0.899829</td>\n",
       "      <td>No Charge after Deductible</td>\n",
       "      <td>0.899829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Family Deductible:</td>\n",
       "      <td>0.899540</td>\n",
       "      <td>$5,700</td>\n",
       "      <td>0.899540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Financial Accumulation Period:</td>\n",
       "      <td>0.898562</td>\n",
       "      <td>Calendar Year</td>\n",
       "      <td>0.898562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UCR:</td>\n",
       "      <td>0.854907</td>\n",
       "      <td>100% of Medicare</td>\n",
       "      <td>0.854907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ER Copay:</td>\n",
       "      <td>0.824926</td>\n",
       "      <td>No Charge after Deductible</td>\n",
       "      <td>0.824926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Family Deductible:</td>\n",
       "      <td>0.802411</td>\n",
       "      <td>$5,700</td>\n",
       "      <td>0.802411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Link to PDML:</td>\n",
       "      <td>0.766787</td>\n",
       "      <td>http://pdml/</td>\n",
       "      <td>0.766787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Coinsurance:</td>\n",
       "      <td>0.757565</td>\n",
       "      <td>30%</td>\n",
       "      <td>0.757565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Modified UCR:</td>\n",
       "      <td>0.680315</td>\n",
       "      <td>Standard</td>\n",
       "      <td>0.680315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Single M.O.O.P.</td>\n",
       "      <td>0.642970</td>\n",
       "      <td>$4,000</td>\n",
       "      <td>0.642970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Plan Design:</td>\n",
       "      <td>0.636063</td>\n",
       "      <td>KACTOHP63RD</td>\n",
       "      <td>0.636063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Single M.O.O.P.</td>\n",
       "      <td>0.599664</td>\n",
       "      <td>$5,850</td>\n",
       "      <td>0.599664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Field Name  Field Name Confidence  \\\n",
       "0                      Specialist:               0.969713   \n",
       "1                  Family M.O.O.P.               0.959258   \n",
       "2                             PCP:               0.946640   \n",
       "3                  Family M.O.O.P.               0.932364   \n",
       "4                     Coinsurance:               0.913815   \n",
       "5                       Inpatient:               0.912482   \n",
       "6         Outpatient Freestanding:               0.899829   \n",
       "7               Family Deductible:               0.899540   \n",
       "8   Financial Accumulation Period:               0.898562   \n",
       "9                             UCR:               0.854907   \n",
       "10                       ER Copay:               0.824926   \n",
       "11              Family Deductible:               0.802411   \n",
       "12                   Link to PDML:               0.766787   \n",
       "13                    Coinsurance:               0.757565   \n",
       "14                   Modified UCR:               0.680315   \n",
       "15                 Single M.O.O.P.               0.642970   \n",
       "16                    Plan Design:               0.636063   \n",
       "17                 Single M.O.O.P.               0.599664   \n",
       "\n",
       "                   Field Value  Field Value Confidence  \n",
       "0   No Charge after Deductible                0.969713  \n",
       "1                       $8,000                0.959258  \n",
       "2   No Charge after Deductible                0.946640  \n",
       "3                      $11.700                0.932364  \n",
       "4                         None                0.913815  \n",
       "5   No Charge after Deductible                0.912482  \n",
       "6   No Charge after Deductible                0.899829  \n",
       "7                       $5,700                0.899540  \n",
       "8                Calendar Year                0.898562  \n",
       "9             100% of Medicare                0.854907  \n",
       "10  No Charge after Deductible                0.824926  \n",
       "11                      $5,700                0.802411  \n",
       "12                http://pdml/                0.766787  \n",
       "13                         30%                0.757565  \n",
       "14                    Standard                0.680315  \n",
       "15                      $4,000                0.642970  \n",
       "16                 KACTOHP63RD                0.636063  \n",
       "17                      $5,850                0.599664  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e4480da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai \n",
    "import pandas as pd\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"C:/Users/Shreshtha/Downloads/balmy-outcome-412805-7a02be612f44.json\"\n",
    "\n",
    "project_id = 'balmy-outcome-412805' \n",
    "location = 'us' \n",
    "processor_id = '1c327dd87f42b98b' \n",
    "processor_version = 'rc' \n",
    "local_file_path = \"C:/Users/Shreshtha/Downloads/ProjectUHC/extracted_images\\Trial 2-2.png\"  # Change this to your downloaded local path\n",
    "mime_type = 'image/png'\n",
    "\n",
    "def online_process(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    ") -> documentai.Document:\n",
    "    \"\"\"\n",
    "    A function to process a document online using Google Document AI.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define an options dictionary, which includes the API's URL. This is used to connect to Google's Document AI service\n",
    "    opts = {\"api_endpoint\": f\"{location}-documentai.googleapis.com\"}\n",
    "\n",
    "    # Create a Document AI client, think of it as our bridge for communicating with Google's services\n",
    "    documentai_client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "\n",
    "    # Generate the complete name of the processor\n",
    "    # You need to first create a processor in the Google Cloud console\n",
    "    resource_name = documentai_client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    # Read in the document you want to analyze (like an image or PDF), and store it in the variable image_content\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "        # Convert the read document into a format that Google Document AI can understand, i.e., a RawDocument object\n",
    "        raw_document = documentai.RawDocument(\n",
    "            content=image_content, mime_type=mime_type\n",
    "        )\n",
    "        # Create a request, which includes the name of the processor and the document we want to analyze\n",
    "        request = documentai.ProcessRequest(\n",
    "            name=resource_name, raw_document=raw_document\n",
    "        )\n",
    "        # Send our request and receive the analysis results\n",
    "        result = documentai_client.process_document(request=request)\n",
    "\n",
    "        # Return this analysis result\n",
    "        return result.document\n",
    "\n",
    "def trim_text(text: str): \n",
    "    \"\"\" Removes spaces and newline characters. \"\"\" \n",
    "    return text.strip().replace(\"\\n\", \" \")\n",
    "\n",
    "# Use the local file path in your function\n",
    "document = online_process(\n",
    "    project_id=project_id,\n",
    "    location=location,\n",
    "    processor_id=processor_id,\n",
    "    file_path=local_file_path,  # Use the local path here\n",
    "    mime_type=mime_type,\n",
    ")\n",
    "\n",
    "names = []\n",
    "name_confidence = []\n",
    "values = []\n",
    "value_confidence = []\n",
    "\n",
    "for page in document.pages:\n",
    "    for field in page.form_fields:\n",
    "        names.append(trim_text(field.field_name.text_anchor.content))\n",
    "        name_confidence.append(field.field_name.confidence)\n",
    "        values.append(trim_text(field.field_value.text_anchor.content))\n",
    "        value_confidence.append(field.field_value.confidence)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Field Name\": names,\n",
    "        \"Field Value\": values\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e693e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "743552cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field Name</th>\n",
       "      <th>Field Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Specialist:</td>\n",
       "      <td>No Charge after Deductible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Family M.O.O.P.</td>\n",
       "      <td>$8,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCP:</td>\n",
       "      <td>No Charge after Deductible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Family M.O.O.P.</td>\n",
       "      <td>$11.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coinsurance:</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Inpatient:</td>\n",
       "      <td>No Charge after Deductible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Outpatient Freestanding:</td>\n",
       "      <td>No Charge after Deductible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Family Deductible:</td>\n",
       "      <td>$5,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Financial Accumulation Period:</td>\n",
       "      <td>Calendar Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UCR:</td>\n",
       "      <td>100% of Medicare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ER Copay:</td>\n",
       "      <td>No Charge after Deductible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Family Deductible:</td>\n",
       "      <td>$5,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Link to PDML:</td>\n",
       "      <td>http://pdml/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Coinsurance:</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Modified UCR:</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Single M.O.O.P.</td>\n",
       "      <td>$4,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Plan Design:</td>\n",
       "      <td>KACTOHP63RD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Single M.O.O.P.</td>\n",
       "      <td>$5,850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Field Name                 Field Value\n",
       "0                      Specialist:  No Charge after Deductible\n",
       "1                  Family M.O.O.P.                      $8,000\n",
       "2                             PCP:  No Charge after Deductible\n",
       "3                  Family M.O.O.P.                     $11.700\n",
       "4                     Coinsurance:                        None\n",
       "5                       Inpatient:  No Charge after Deductible\n",
       "6         Outpatient Freestanding:  No Charge after Deductible\n",
       "7               Family Deductible:                      $5,700\n",
       "8   Financial Accumulation Period:               Calendar Year\n",
       "9                             UCR:            100% of Medicare\n",
       "10                       ER Copay:  No Charge after Deductible\n",
       "11              Family Deductible:                      $5,700\n",
       "12                   Link to PDML:                http://pdml/\n",
       "13                    Coinsurance:                         30%\n",
       "14                   Modified UCR:                    Standard\n",
       "15                 Single M.O.O.P.                      $4,000\n",
       "16                    Plan Design:                 KACTOHP63RD\n",
       "17                 Single M.O.O.P.                      $5,850"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc060862",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'storage' from 'google.cloud' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m documentai \n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m storage\n\u001b[0;32m      7\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGOOGLE_APPLICATION_CREDENTIALS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/Shreshtha/Downloads/balmy-outcome-412805-7a02be612f44.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m project_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalmy-outcome-412805\u001b[39m\u001b[38;5;124m'\u001b[39m \n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'storage' from 'google.cloud' (unknown location)"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai \n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"C:/Users/Shreshtha/Downloads/balmy-outcome-412805-7a02be612f44.json\"\n",
    "\n",
    "project_id = 'balmy-outcome-412805' \n",
    "location = 'us' \n",
    "processor_id = '1c327dd87f42b98b' \n",
    "processor_version = 'rc' \n",
    "gcs_bucket = 'your-gcs-bucket'  # Replace with your GCS bucket name\n",
    "output_folder = 'path/to/save/output'  # Change this to your desired local output folder\n",
    "mime_type = 'image/png'\n",
    "\n",
    "def download_file_from_gcs(bucket_name, blob_name, local_path):\n",
    "    \"\"\"Download a file from Google Cloud Storage to a local path.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.download_to_filename(local_path)\n",
    "\n",
    "def online_process(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    ") -> documentai.Document:\n",
    "    \"\"\"\n",
    "    A function to process a document online using Google Document AI.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define an options dictionary, which includes the API's URL. This is used to connect to Google's Document AI service\n",
    "    opts = {\"api_endpoint\": f\"{location}-documentai.googleapis.com\"}\n",
    "\n",
    "    # Create a Document AI client, think of it as our bridge for communicating with Google's services\n",
    "    documentai_client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "\n",
    "    # Generate the complete name of the processor\n",
    "    # You need to first create a processor in the Google Cloud console\n",
    "    resource_name = documentai_client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    # Read in the document you want to analyze (like an image or PDF), and store it in the variable image_content\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "        # Convert the read document into a format that Google Document AI can understand, i.e., a RawDocument object\n",
    "        raw_document = documentai.RawDocument(\n",
    "            content=image_content, mime_type=mime_type\n",
    "        )\n",
    "        # Create a request, which includes the name of the processor and the document we want to analyze\n",
    "        request = documentai.ProcessRequest(\n",
    "            name=resource_name, raw_document=raw_document\n",
    "        )\n",
    "        # Send our request and receive the analysis results\n",
    "        result = documentai_client.process_document(request=request)\n",
    "\n",
    "        # Return this analysis result\n",
    "        return result.document\n",
    "\n",
    "def trim_text(text: str): \n",
    "    \"\"\" Removes spaces and newline characters. \"\"\" \n",
    "    return text.strip().replace(\"\\n\", \" \")\n",
    "\n",
    "# Get a list of all files in the GCS bucket\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(gcs_bucket)\n",
    "blobs = bucket.list_blobs()\n",
    "\n",
    "# Process each image in the bucket\n",
    "for blob in blobs:\n",
    "    file_name = os.path.basename(blob.name)\n",
    "    local_file_path = os.path.join(output_folder, file_name)\n",
    "    \n",
    "    # Download the file from GCS to a local path\n",
    "    download_file_from_gcs(gcs_bucket, blob.name, local_file_path)\n",
    "\n",
    "    # Use the local file path in your function\n",
    "    document = online_process(\n",
    "        project_id=project_id,\n",
    "        location=location,\n",
    "        processor_id=processor_id,\n",
    "        file_path=local_file_path,\n",
    "        mime_type=mime_type,\n",
    "    )\n",
    "\n",
    "    names = []\n",
    "    values = []\n",
    "\n",
    "    for page in document.pages:\n",
    "        for field in page.form_fields:\n",
    "            names.append(trim_text(field.field_name.text_anchor.content))\n",
    "            values.append(trim_text(field.field_value.text_anchor.content))\n",
    "\n",
    "    # Create a DataFrame for each document\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Field Name\": names,\n",
    "            \"Field Value\": values\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Optionally, you can save each DataFrame to a CSV file or process the data as needed\n",
    "    output_csv_path = os.path.join(output_folder, f\"{file_name}_output.csv\")\n",
    "    df.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be74fc54",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'storage' from 'google.cloud' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m documentai_v1 \u001b[38;5;28;01mas\u001b[39;00m documentai\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m storage\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'storage' from 'google.cloud' (unknown location)"
     ]
    }
   ],
   "source": [
    "from google.cloud import documentai_v1 as documentai\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"C:/Users/Shreshtha/Downloads/balmy-outcome-412805-7a02be612f44.json\"\n",
    "\n",
    "project_id = 'balmy-outcome-412805'\n",
    "location = 'us'\n",
    "processor_id = '1c327dd87f42b98b'\n",
    "processor_version = 'rc'\n",
    "gcs_bucket = 'your-gcs-bucket'  # Replace with your GCS bucket name\n",
    "output_folder = 'path/to/save/output'  # Change this to your desired local output folder\n",
    "mime_type = 'image/png'\n",
    "\n",
    "def download_file_from_gcs(bucket_name, blob_name, local_path):\n",
    "    \"\"\"Download a file from Google Cloud Storage to a local path.\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.download_to_filename(local_path)\n",
    "\n",
    "def online_process(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    ") -> documentai.Document:\n",
    "    \"\"\"\n",
    "    A function to process a document online using Google Document AI.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define an options dictionary, which includes the API's URL. This is used to connect to Google's Document AI service\n",
    "    opts = {\"api_endpoint\": f\"{location}-documentai.googleapis.com\"}\n",
    "\n",
    "    # Create a Document AI client, think of it as our bridge for communicating with Google's services\n",
    "    documentai_client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "\n",
    "    # Generate the complete name of the processor\n",
    "    # You need to first create a processor in the Google Cloud console\n",
    "    resource_name = documentai_client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    # Read in the document you want to analyze (like an image or PDF), and store it in the variable image_content\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "        # Convert the read document into a format that Google Document AI can understand, i.e., a RawDocument object\n",
    "        raw_document = documentai.RawDocument(\n",
    "            content=image_content, mime_type=mime_type\n",
    "        )\n",
    "        # Create a request, which includes the name of the processor and the document we want to analyze\n",
    "        request = documentai.ProcessRequest(\n",
    "            name=resource_name, raw_document=raw_document\n",
    "        )\n",
    "        # Send our request and receive the analysis results\n",
    "        result = documentai_client.process_document(request=request)\n",
    "\n",
    "        # Return this analysis result\n",
    "        return result.document\n",
    "\n",
    "def trim_text(text: str): \n",
    "    \"\"\" Removes spaces and newline characters. \"\"\" \n",
    "    return text.strip().replace(\"\\n\", \" \")\n",
    "\n",
    "# Get a list of all files in the GCS bucket\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket(gcs_bucket)\n",
    "blobs = list(bucket.list_blobs())\n",
    "\n",
    "# Process each image in the bucket\n",
    "for blob in blobs:\n",
    "    file_name = os.path.basename(blob.name)\n",
    "    local_file_path = os.path.join(output_folder, file_name)\n",
    "    \n",
    "    # Download the file from GCS to a local path\n",
    "    download_file_from_gcs(gcs_bucket, blob.name, local_file_path)\n",
    "\n",
    "    # Use the local file path in your function\n",
    "    document = online_process(\n",
    "        project_id=project_id,\n",
    "        location=location,\n",
    "        processor_id=processor_id,\n",
    "        file_path=local_file_path,\n",
    "        mime_type=mime_type,\n",
    "    )\n",
    "\n",
    "    names = []\n",
    "    values = []\n",
    "\n",
    "    for page in document.pages:\n",
    "        for field in page.form_fields:\n",
    "            names.append(trim_text(field.field_name.text_anchor.content))\n",
    "            values.append(trim_text(field.field_value.text_anchor.content))\n",
    "\n",
    "    # Create a DataFrame for each document\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Field Name\": names,\n",
    "            \"Field Value\": values\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Optionally, you can save each DataFrame to a CSV file or process the data as needed\n",
    "    output_csv_path = os.path.join(output_folder, f\"{file_name}_output.csv\")\n",
    "    df.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64e25fc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'storage' from 'google.cloud' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m documentai_v1 \u001b[38;5;28;01mas\u001b[39;00m documentai\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m storage\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'storage' from 'google.cloud' (unknown location)"
     ]
    }
   ],
   "source": [
    "from google.cloud import documentai_v1 as documentai\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"C:/Users/Shreshtha/Downloads/balmy-outcome-412805-7a02be612f44.json\"\n",
    "\n",
    "project_id = 'balmy-outcome-412805'\n",
    "location = 'us'\n",
    "processor_id = '1c327dd87f42b98b'\n",
    "processor_version = 'rc'\n",
    "gcs_bucket = 'your-gcs-bucket'  # Replace with your GCS bucket name\n",
    "output_folder = 'path/to/save/output'  # Change this to your desired local output folder\n",
    "mime_type = 'image/png'\n",
    "\n",
    "def download_file_from_gcs(bucket_name, blob_name, local_path):\n",
    "    \"\"\"Download a file from Google Cloud Storage to a local path.\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.download_to_filename(local_path)\n",
    "\n",
    "def online_process(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    ") -> documentai.Document:\n",
    "    \"\"\"\n",
    "    A function to process a document online using Google Document AI.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define an options dictionary, which includes the API's URL. This is used to connect to Google's Document AI service\n",
    "    opts = {\"api_endpoint\": f\"{location}-documentai.googleapis.com\"}\n",
    "\n",
    "    # Create a Document AI client, think of it as our bridge for communicating with Google's services\n",
    "    documentai_client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "\n",
    "    # Generate the complete name of the processor\n",
    "    # You need to first create a processor in the Google Cloud console\n",
    "    resource_name = documentai_client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    # Read in the document you want to analyze (like an image or PDF), and store it in the variable image_content\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "        # Convert the read document into a format that Google Document AI can understand, i.e., a RawDocument object\n",
    "        raw_document = documentai.RawDocument(\n",
    "            content=image_content, mime_type=mime_type\n",
    "        )\n",
    "        # Create a request, which includes the name of the processor and the document we want to analyze\n",
    "        request = documentai.ProcessRequest(\n",
    "            name=resource_name, raw_document=raw_document\n",
    "        )\n",
    "        # Send our request and receive the analysis results\n",
    "        result = documentai_client.process_document(request=request)\n",
    "\n",
    "        # Return this analysis result\n",
    "        return result.document\n",
    "\n",
    "def trim_text(text: str): \n",
    "    \"\"\" Removes spaces and newline characters. \"\"\" \n",
    "    return text.strip().replace(\"\\n\", \" \")\n",
    "\n",
    "# Get a list of all files in the GCS bucket\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket(gcs_bucket)\n",
    "blobs = list(bucket.list_blobs())\n",
    "\n",
    "# Process each image in the bucket\n",
    "for blob in blobs:\n",
    "    file_name = os.path.basename(blob.name)\n",
    "    local_file_path = os.path.join(output_folder, file_name)\n",
    "    \n",
    "    # Download the file from GCS to a local path\n",
    "    download_file_from_gcs(gcs_bucket, blob.name, local_file_path)\n",
    "\n",
    "    # Use the local file path in your function\n",
    "    document = online_process(\n",
    "        project_id=project_id,\n",
    "        location=location,\n",
    "        processor_id=processor_id,\n",
    "        file_path=local_file_path,\n",
    "        mime_type=mime_type,\n",
    "    )\n",
    "\n",
    "    names = []\n",
    "    values = []\n",
    "\n",
    "    for page in document.pages:\n",
    "        for field in page.form_fields:\n",
    "            names.append(trim_text(field.field_name.text_anchor.content))\n",
    "            values.append(trim_text(field.field_value.text_anchor.content))\n",
    "\n",
    "    # Create a DataFrame for each document\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Field Name\": names,\n",
    "            \"Field Value\": values\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Optionally, you can save each DataFrame to a CSV file or process the data as needed\n",
    "    output_csv_path = os.path.join(output_folder, f\"{file_name}_output.csv\")\n",
    "    df.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c21410c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-documentai in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (2.21.1)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.14.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (2.1.3)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (2.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-cloud-documentai) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-cloud-documentai) (4.23.4)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.23.3 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-cloud-storage) (2.27.0)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0 (from google-cloud-storage)\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.6.0 (from google-cloud-storage)\n",
      "  Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from google-cloud-storage) (2.31.0)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage)\n",
      "  Downloading google_crc32c-1.5.0-cp311-cp311-win_amd64.whl (27 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (1.62.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (1.60.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shreshtha\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2023.11.17)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\shreshtha\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.23.3->google-cloud-storage) (0.4.8)\n",
      "Downloading google_cloud_storage-2.14.0-py2.py3-none-any.whl (121 kB)\n",
      "   ---------------------------------------- 0.0/121.6 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/121.6 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 30.7/121.6 kB 660.6 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 30.7/121.6 kB 660.6 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 30.7/121.6 kB 660.6 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 41.0/121.6 kB 178.6 kB/s eta 0:00:01\n",
      "   ------------------- ------------------- 61.4/121.6 kB 218.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- 121.6/121.6 kB 396.2 kB/s eta 0:00:00\n",
      "Downloading pandas-2.2.0-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.6 MB 3.6 MB/s eta 0:00:04\n",
      "   ---------------------------------------- 0.1/11.6 MB 3.6 MB/s eta 0:00:04\n",
      "   ---------------------------------------- 0.1/11.6 MB 3.6 MB/s eta 0:00:04\n",
      "   ---------------------------------------- 0.1/11.6 MB 3.6 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.2/11.6 MB 697.2 kB/s eta 0:00:17\n",
      "    --------------------------------------- 0.2/11.6 MB 692.4 kB/s eta 0:00:17\n",
      "    --------------------------------------- 0.2/11.6 MB 686.8 kB/s eta 0:00:17\n",
      "    --------------------------------------- 0.3/11.6 MB 737.3 kB/s eta 0:00:16\n",
      "   - -------------------------------------- 0.3/11.6 MB 776.5 kB/s eta 0:00:15\n",
      "   - -------------------------------------- 0.4/11.6 MB 823.4 kB/s eta 0:00:14\n",
      "   - -------------------------------------- 0.5/11.6 MB 887.1 kB/s eta 0:00:13\n",
      "   - -------------------------------------- 0.5/11.6 MB 891.2 kB/s eta 0:00:13\n",
      "   - -------------------------------------- 0.6/11.6 MB 901.1 kB/s eta 0:00:13\n",
      "   -- ------------------------------------- 0.6/11.6 MB 914.3 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.7/11.6 MB 925.7 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.7/11.6 MB 954.2 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.7/11.6 MB 954.2 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.7/11.6 MB 825.0 kB/s eta 0:00:14\n",
      "   -- ------------------------------------- 0.7/11.6 MB 791.2 kB/s eta 0:00:14\n",
      "   --- ------------------------------------ 0.9/11.6 MB 924.1 kB/s eta 0:00:12\n",
      "   --- ------------------------------------ 1.0/11.6 MB 972.8 kB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.0/11.6 MB 924.8 kB/s eta 0:00:12\n",
      "   --- ------------------------------------ 1.0/11.6 MB 924.8 kB/s eta 0:00:12\n",
      "   --- ------------------------------------ 1.0/11.6 MB 924.8 kB/s eta 0:00:12\n",
      "   --- ------------------------------------ 1.0/11.6 MB 851.2 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.1/11.6 MB 884.7 kB/s eta 0:00:12\n",
      "   --- ------------------------------------ 1.2/11.6 MB 884.3 kB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 1.2/11.6 MB 873.4 kB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 1.3/11.6 MB 910.4 kB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 1.3/11.6 MB 911.5 kB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 1.4/11.6 MB 921.6 kB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 1.5/11.6 MB 953.2 kB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 1.5/11.6 MB 956.5 kB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 1.5/11.6 MB 929.8 kB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 1.6/11.6 MB 946.4 kB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 1.7/11.6 MB 965.5 kB/s eta 0:00:11\n",
      "   ------ --------------------------------- 1.8/11.6 MB 988.9 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.8/11.6 MB 977.4 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.9/11.6 MB 994.0 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.9/11.6 MB 996.3 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 2.0/11.6 MB 988.1 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 2.0/11.6 MB 988.2 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 2.0/11.6 MB 960.9 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.0/11.6 MB 954.1 kB/s eta 0:00:11\n",
      "   ------- -------------------------------- 2.1/11.6 MB 975.9 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.2/11.6 MB 973.7 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.2/11.6 MB 985.1 kB/s eta 0:00:10\n",
      "   -------- ------------------------------- 2.3/11.6 MB 1.0 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 2.4/11.6 MB 1.0 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.5/11.6 MB 1.0 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.5/11.6 MB 1.0 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.5/11.6 MB 1.0 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.5/11.6 MB 1.0 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.8/11.6 MB 1.1 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.8/11.6 MB 1.1 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.9/11.6 MB 1.1 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.9/11.6 MB 1.0 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 2.9/11.6 MB 1.0 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.0/11.6 MB 1.0 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.0/11.6 MB 1.0 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.1/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 3.2/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 3.3/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 3.3/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 3.4/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.5/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.6/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.6/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.6/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.6/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.7/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 3.8/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 3.9/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.0/11.6 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 4.0/11.6 MB 1.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.1/11.6 MB 1.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.2/11.6 MB 1.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.3/11.6 MB 1.1 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.4/11.6 MB 1.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.4/11.6 MB 1.1 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.5/11.6 MB 1.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.6/11.6 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 4.7/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.7/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.8/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.8/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.9/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 5.0/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 5.0/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 5.0/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 5.1/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 5.1/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.2/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.3/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.4/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.4/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.4/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.5/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.6/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.6/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.7/11.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.8/11.6 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 5.9/11.6 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 5.9/11.6 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 6.0/11.6 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.1/11.6 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.2/11.6 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.3/11.6 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.3/11.6 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.5/11.6 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.6/11.6 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.6/11.6 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 6.7/11.6 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 6.8/11.6 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 6.9/11.6 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 7.0/11.6 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 7.1/11.6 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 7.1/11.6 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.2/11.6 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.3/11.6 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.4/11.6 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.4/11.6 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.5/11.6 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.6/11.6 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.7/11.6 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.8/11.6 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.9/11.6 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.9/11.6 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.9/11.6 MB 1.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 8.1/11.6 MB 1.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 8.2/11.6 MB 1.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 8.3/11.6 MB 1.3 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.4/11.6 MB 1.3 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.5/11.6 MB 1.3 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.6/11.6 MB 1.3 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.7/11.6 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.8/11.6 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.8/11.6 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.9/11.6 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 9.0/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.0/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.1/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.2/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.3/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.3/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.4/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.5/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.6/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.6/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.7/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.7/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.8/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.8/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.9/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.0/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.0/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.1/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.1/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.2/11.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.3/11.6 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.4/11.6 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.6/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.7/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.8/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.9/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.0/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.1/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.1/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.2/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.3/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.3/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.3/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.4/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl (80 kB)\n",
      "   ---------------------------------------- 0.0/80.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 80.6/80.6 kB 4.4 MB/s eta 0:00:00\n",
      "Installing collected packages: google-crc32c, pandas, google-resumable-media, google-cloud-core, google-cloud-storage\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.1.3\n",
      "    Uninstalling pandas-2.1.3:\n",
      "      Successfully uninstalled pandas-2.1.3\n",
      "Successfully installed google-cloud-core-2.4.1 google-cloud-storage-2.14.0 google-crc32c-1.5.0 google-resumable-media-2.7.0 pandas-2.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Shreshtha\\AppData\\Roaming\\Python\\Python311\\site-packages\\~andas.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Shreshtha\\AppData\\Roaming\\Python\\Python311\\site-packages\\~andas'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-documentai google-cloud-storage pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "807b2f55",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.io.formats.csvs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 106\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Optionally, you can save each DataFrame to a CSV file or process the data as needed\u001b[39;00m\n\u001b[0;32m    105\u001b[0m output_csv_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_output.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 106\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(output_csv_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\formats\\format.py:1125\u001b[0m, in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas.io.formats.csvs'"
     ]
    }
   ],
   "source": [
    "from google.cloud import documentai_v1 as documentai\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"C:/Users/Shreshtha/Downloads/balmy-outcome-412805-7a02be612f44.json\"\n",
    "\n",
    "project_id = 'balmy-outcome-412805'\n",
    "location = 'us'\n",
    "processor_id = '1c327dd87f42b98b'\n",
    "processor_version = 'rc'\n",
    "gcs_bucket = 'blogtrial'  # Replace with your GCS bucket name\n",
    "output_folder = \"C:/Users/Shreshtha/Downloads/ProjectUHC/extracted_images\" # Change this to your desired local output folder\n",
    "mime_type = 'image/png'\n",
    "\n",
    "def download_file_from_gcs(bucket_name, blob_name, local_path):\n",
    "    \"\"\"Download a file from Google Cloud Storage to a local path.\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.download_to_filename(local_path)\n",
    "\n",
    "def online_process(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    ") -> documentai.Document:\n",
    "    \"\"\"\n",
    "    A function to process a document online using Google Document AI.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define an options dictionary, which includes the API's URL. This is used to connect to Google's Document AI service\n",
    "    opts = {\"api_endpoint\": f\"{location}-documentai.googleapis.com\"}\n",
    "\n",
    "    # Create a Document AI client, think of it as our bridge for communicating with Google's services\n",
    "    documentai_client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "\n",
    "    # Generate the complete name of the processor\n",
    "    # You need to first create a processor in the Google Cloud console\n",
    "    resource_name = documentai_client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    # Read in the document you want to analyze (like an image or PDF), and store it in the variable image_content\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "        # Convert the read document into a format that Google Document AI can understand, i.e., a RawDocument object\n",
    "        raw_document = documentai.RawDocument(\n",
    "            content=image_content, mime_type=mime_type\n",
    "        )\n",
    "        # Create a request, which includes the name of the processor and the document we want to analyze\n",
    "        request = documentai.ProcessRequest(\n",
    "            name=resource_name, raw_document=raw_document\n",
    "        )\n",
    "        # Send our request and receive the analysis results\n",
    "        result = documentai_client.process_document(request=request)\n",
    "\n",
    "        # Return this analysis result\n",
    "        return result.document\n",
    "\n",
    "def trim_text(text: str): \n",
    "    \"\"\" Removes spaces and newline characters. \"\"\" \n",
    "    return text.strip().replace(\"\\n\", \" \")\n",
    "\n",
    "# Get a list of all files in the GCS bucket\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket(gcs_bucket)\n",
    "blobs = list(bucket.list_blobs())\n",
    "\n",
    "# Process each image in the bucket\n",
    "for blob in blobs:\n",
    "    file_name = os.path.basename(blob.name)\n",
    "    local_file_path = os.path.join(output_folder, file_name)\n",
    "    \n",
    "    # Download the file from GCS to a local path\n",
    "    download_file_from_gcs(gcs_bucket, blob.name, local_file_path)\n",
    "\n",
    "    # Use the local file path in your function\n",
    "    document = online_process(\n",
    "        project_id=project_id,\n",
    "        location=location,\n",
    "        processor_id=processor_id,\n",
    "        file_path=local_file_path,\n",
    "        mime_type=mime_type,\n",
    "    )\n",
    "\n",
    "    names = []\n",
    "    values = []\n",
    "\n",
    "    for page in document.pages:\n",
    "        for field in page.form_fields:\n",
    "            names.append(trim_text(field.field_name.text_anchor.content))\n",
    "            values.append(trim_text(field.field_value.text_anchor.content))\n",
    "\n",
    "    # Create a DataFrame for each document\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Field Name\": names,\n",
    "            \"Field Value\": values\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Optionally, you can save each DataFrame to a CSV file or process the data as needed\n",
    "    output_csv_path = os.path.join(output_folder, f\"{file_name}_output.csv\")\n",
    "    df.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8f99020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import documentai_v1 as documentai\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"C:/Users/Shreshtha/Downloads/balmy-outcome-412805-7a02be612f44.json\"\n",
    "\n",
    "project_id = 'balmy-outcome-412805'\n",
    "location = 'us'\n",
    "processor_id = '1c327dd87f42b98b'\n",
    "processor_version = 'rc'\n",
    "gcs_bucket = 'blogtrial'  # Replace with your GCS bucket name\n",
    "output_folder = \"C:/Users/Shreshtha/Downloads/ProjectUHC/extracted_images\" # Change this to your desired local output folder\n",
    "mime_type = 'image/png'\n",
    "\n",
    "def download_file_from_gcs(bucket_name, blob_name, local_path):\n",
    "    \"\"\"Download a file from Google Cloud Storage to a local path.\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.download_to_filename(local_path)\n",
    "\n",
    "def online_process(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    ") -> documentai.Document:\n",
    "    \"\"\"\n",
    "    A function to process a document online using Google Document AI.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define an options dictionary, which includes the API's URL. This is used to connect to Google's Document AI service\n",
    "    opts = {\"api_endpoint\": f\"{location}-documentai.googleapis.com\"}\n",
    "\n",
    "    # Create a Document AI client, think of it as our bridge for communicating with Google's services\n",
    "    documentai_client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "\n",
    "    # Generate the complete name of the processor\n",
    "    # You need to first create a processor in the Google Cloud console\n",
    "    resource_name = documentai_client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    # Read in the document you want to analyze (like an image or PDF), and store it in the variable image_content\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "        # Convert the read document into a format that Google Document AI can understand, i.e., a RawDocument object\n",
    "        raw_document = documentai.RawDocument(\n",
    "            content=image_content, mime_type=mime_type\n",
    "        )\n",
    "        # Create a request, which includes the name of the processor and the document we want to analyze\n",
    "        request = documentai.ProcessRequest(\n",
    "            name=resource_name, raw_document=raw_document\n",
    "        )\n",
    "        # Send our request and receive the analysis results\n",
    "        result = documentai_client.process_document(request=request)\n",
    "\n",
    "        # Return this analysis result\n",
    "        return result.document\n",
    "\n",
    "def trim_text(text: str): \n",
    "    \"\"\" Removes spaces and newline characters. \"\"\" \n",
    "    return text.strip().replace(\"\\n\", \" \")\n",
    "\n",
    "# Get a list of all files in the GCS bucket\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket(gcs_bucket)\n",
    "blobs = list(bucket.list_blobs())\n",
    "\n",
    "# Process each image in the bucket\n",
    "for blob in blobs:\n",
    "    file_name = os.path.basename(blob.name)\n",
    "    local_file_path = os.path.join(output_folder, file_name)\n",
    "    \n",
    "    # Download the file from GCS to a local path\n",
    "    download_file_from_gcs(gcs_bucket, blob.name, local_file_path)\n",
    "\n",
    "    # Use the local file path in your function\n",
    "    document = online_process(\n",
    "        project_id=project_id,\n",
    "        location=location,\n",
    "        processor_id=processor_id,\n",
    "        file_path=local_file_path,\n",
    "        mime_type=mime_type,\n",
    "    )\n",
    "\n",
    "    names = []\n",
    "    values = []\n",
    "\n",
    "    for page in document.pages:\n",
    "        for field in page.form_fields:\n",
    "            names.append(trim_text(field.field_name.text_anchor.content))\n",
    "            values.append(trim_text(field.field_value.text_anchor.content))\n",
    "\n",
    "     # Create a DataFrame for each document\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Field Name\": names,\n",
    "        \"Field Value\": values\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff7317ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62418257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field Name</th>\n",
       "      <th>Field Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MN5030</td>\n",
       "      <td> 0 w</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Field Name Field Value\n",
       "0     MN5030     0 w"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
